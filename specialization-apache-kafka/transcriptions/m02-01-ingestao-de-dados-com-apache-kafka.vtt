Então, vamos lá, gente.
Vamos lá.
Dia 2, segunda aula aqui.
Nossa, vamos fazer um recap rapidinho do
que a gente viu ontem, para todo mundo
que está na mesma página aqui, e a gente
também já começar a ligar os pontos.
Então, a gente entendeu um pouco mais da
arquitetura do Kafka.
A gente entendeu que o broker é o
principal componente dentro do Kafka.
O broker, quando a gente fala de broker,
é o servidor do algoritmo do Kafka, e
onde reside as informações.
Então, pensa no Kafka como um discão, um
discão extremamente inteligente.
A inteligência do Kafka está dentro do
broker.
Então, o broker é o cara que armazena o
dado, comunica entre eles.
Eu tenho APIs.
Eu tenho APIs de producer, eu tenho APIs
de Kafka Connect, eu trabalho com
clusters de Zookeeper, ou eu posso usar
o Craft, ou já está em produção.
Eu não tenho necessidade de Zookeeper
mais, se eu praticamente trabalhar de
broker para broker.
Porque eu tenho um ganho de performance,
evolução, como eu comentei, da 4 .0 em
diante, o Zookeeper vai entrar como
deprecated.
Então, para quem...
Estamos na 3 .8.
Então, para quem está nesse ambiente, eu
já recomendo já pensar em migrações.
Porque depois vai ser muito mais
doloroso.
Eu sempre falo, tenta fazer uma migração
de versão uma mais próxima da
outra, porque senão você pode ter algum
problema de incompatibilidade muito
grande, ou um tipo de função que você
está usando, ou código que você está
usando dentro daquela versão que entrou
em deprecated e não está sendo usado
mais.
Então, tomar muito cuidado.
Ou até mesmo, toda uma arquitetura em
cima de Zookeeper, uma automação em cima
de Zookeeper, que vai ter que
praticamente refazer de uma outra forma.
Então, fica o recado.
Outra coisa importante, tá?
Eu sempre recomendo, gente, trabalhar
com Kafka uma ou duas versões da última.
Por quê?
Porque o Kafka, ele não tem tantas
atualizações assim, mas é bom a gente
testar aos poucos.
Então, geralmente, por exemplo, nós
estamos na 3 .8, tá?
Eu estou na 3 .7 .1.
Então, eu tenho 3 .7 .2 e vou para 3 .8.
Então, tomem cuidado aí na hora de fazer
essas mudanças.
Tecnologia, eu não gosto sempre de pegar
a última na última, não.
Eu testo a última na última.
Mas em produção, tomar esse cuidado, tá?
Então, a gente viu como é que Kafka
funciona, a gente viu a parte de
arquitetura, a gente entendeu o
HDInsight, a gente falou de MSK, a gente
falou também de Kubernetes, né?
Vocês viram o deployment que eu tenho do
Streams, né?
Como é que a gente vai trabalhar com
ele, questão de custo, né?
O evento, isso aqui é importante.
Um mando e um invendo, eu tenho o
cabeçalho, eu tenho a chave, o valor.
Lembrando que para estratégia de
particionamento, a gente vai falar muito
nessa aula disso aqui, tá?
Particionamento, eu tenho, eu tenho a
chave, eu tenho aqui o valor daquela
minha mensagem, tá?
Então, e eu tenho a questão do tópico,
que é a representação da tabela.
Eu tenho partição, que é onde ele é
dividido e distribuído dentro do meu
tópico, dentro do meu broker.
Tudo isso aqui é lógico, tá?
É lógico.
E eu tenho o offset, que é a posição
lógica aonde o meu dado reside.
Então, aqui, pelo offset, eu sei
coordenar em que ponto que esses caras
estão produzindo, em que esses caras
estão, lendo.
E a gente vai ver ainda mais claro hoje,
começa hoje a enclarecer um pouco mais
essa relação do offset e offset, tá?
Na parte de produção.
A gente viu o de log compacto, né?
O que log compacto, o que ele é?
Normalmente, do Kafka, quando eu faço
sem um log comum, um tópico de
configuração padrão, sem nenhum tipo de
modificação, ele vai ser um change log.
Eu posso mandar eventos e ele vai só
adicionar.
Ele não vai fazer nenhum tipo de update.
Update aqui, tá?
Então, se eu mandei com a mesma chave,
um valor Matheus, mandei com um valor
mais chave, um valor Luan, ele vai
adicionar os dois.
Ele vai fazendo append.
Ele sempre vai ser um append log.
Porém, em alguns casos, é interessante
eu pensar em compactar isso.
Eu não quero ver o dado como um todo.
Eu quero ver somente o último.
Para mim, é importante.
Então, para mim, nesse processo, por
exemplo, o que importa é a chave 1 e a
chave 2.
Então, minha chave, o K1 aqui, é o
Leonardo, ele que eu quero ver.
Então, está aqui.
Eu crio uma configuração para compactar.
Lembrando que, a partir do momento que
eu faço isso, eu não acesso a informação
mais.
Por quê?
Porque eu marco aqueles dados antes para
serem limpos.
Então, eu vou ter uma rotina que vai
limpar os dados que estão aqui para a
gente poder trabalhar.
Vimos isso aqui também.
Descer aqui.
Aqui, vi uma relação entre um produto e
um consumo.
Aqui, eles são desacoplados.
O que acontecer de um lado, não afeta o
outro.
E vice -versa.
Totalmente desacoplado.
Então, a gente não tem nenhum problema
aqui.
A gente viu também a questão da
liderança.
Isso aqui é importante.
Estou mandando o dado para o meu líder.
Ele vai replicar os dados entre os meus
followers baseados na regra que eu
coloquei no meu tópico.
Qual que é o fator de replicação desse
tópico aqui?
Sem olhar, eu já sei que o fator de
replicação é igual a 3.
Onde eu tenho um líder e dois followers.
Se eu tivesse fator de replicação, igual
a 2, eu teria um líder e um follower
apenas.
O qual ele ia escolher baseado em quem
respondeu mais rápido no momento de
gravar.
Beleza?
A gente vai explicar um pouquinho mais
desse cara aqui.
De novo, eu falei do craft, né?
E a gente começa agora já entendendo já
esse cara.
Então, agora ficou muito claro.
Vamos botar o craft aqui.
Eu acho que ficou mais bonitinho o
desenho no craft.
A gente entendeu esse cara.
O que quebrou, o que...
Entendeu o macro, né?
Eu sempre falo que...
Pegamos o highlight, né?
O high level.
O que que é?
Pessoal, entendemos que o craft é o cara
que vai armazenar.
A gente vai falar agora da inserção.
Temos alguma dúvida?
Me mandem aí.
Por favor.
Eu leo.
Ótimo.
Eu vou...
Ótimo.
Eu gosto disso.
Vamos...
Eu leo primeiro.
Pode perguntar.
Por favor.
Boa noite.
Só uma dúvida em relação ao Logo
Compaction.
Ele faz a...
Ele faz a compactação baseado no
timestamp da entrada do dado no tópico?
Da chave.
Chave mais timestamp.
Ah, tá.
Chave mais timestamp.
Principalmente...
O timestamp é obrigatório no header.
A chave, não.
Pra você conseguir fazer o Logo
Compacto, vai pegar o seguinte.
Chave mais o último timestamp e o valor.
É tipo um enjanelamento, né?
Uma função window que faz o
particionamento.
Isso.
Internamente, sim.
Aham.
Obrigado.
Valeu.
Nada.
João, deixa eu...
Pode tirar aí.
É...
Eu...
Eu fiquei curioso quanto à questão de
como que é feita a limpeza dos dados ali
quando eles são marcados com o Dirty.
Ele segue o mesmo padrão assim de um
garbage collection?
Como é que funciona?
Exatamente.
De um garbage collection.
Exatamente.
Tá?
Ele vai marcar aqueles segmentos,
aqueles arquivos de segmento que eu
comentei.
Vai marcar a posição que tá lá dentro,
que tem lá dentro essa informação.
Vai falar assim, olha, esse arquivo aqui
é o arquivo que eu preciso deletar.
Ele tem esse dado aqui que tá marcado.
Se ele vai lá, ele limpa o arquivo.
E esse processamento de garbage
collection, ele acontece em paralelo com
a ingestão?
Ele não interrompe a ingestão, por
exemplo?
Totalmente separado.
Totalmente separado.
É dentro do próprio broker, mas é
separado.
Entendi.
Como ele é só um append, e a gente vai
ver algumas coisas aqui, como é só um
append log, então ele não tem nenhum
tipo de influência sobre a ingestão,
não.
Entendi.
Perfeito.
Obrigado.
De nada.
Mais alguma dúvida, pessoal?
Vamos seguir agora para o dia 2?
Todo mundo preparado?
Thiago, perfeito.
Gente, vamos lá, não tinha dúvida.
Pode desmutar, Thiago.
Boa noite, pessoal.
Matheus, eu queria só ter uma
curiosidade mesmo.
Se tem algum tipo de boas práticas para
se definir a quantidade de réplicas que
a gente seleciona, por exemplo, se uma
database for muito grande, se a gente
coloca 4 ou 5, por exemplo.
Existe isso?
Um tipo de cálculo que quer ser feito?
Não cálculo, mas existem boas práticas
em questão de como é que você vai montar
o seu ambiente.
Porque geralmente, no último dia, eu
falo dos ambientes, mas só adiantando um
pouco como é que funciona.
Você pega como é que a gente fala
quantas réplicas que eu vou ter, o
workload que eu vou ter, o que é de
durabilidade, e de novo, as réplicas é
questão da durabilidade.
O dado vai ficar lá, o dado vai ficar
lá, eu posso ter perca de dado, eu tenho
que ter uma réplica online o tempo
inteiro.
Qual a criatividade daquele ambiente?
Tem uma série de coisas que a gente leva
em consideração.
O qual eu mostro isso, ambientes de alta
durabilidade, alta disponibilidade.
De novo, é importante que a gente vai
ter que abrir mão de uma coisa.
Se eu quiser alta durabilidade, eu vou
ter o dado replicado em diversos
lugares, eu vou perder tempo.
Então, eu não posso ter uma alta
latência.
Não vou passar uma baixa latência, quer
dizer, nesse caso.
Eu aceitei porque, de novo, aqui a gente
vai sempre ter uma moeda de troca.
Eu não vou ter nenhum...
Uma durabilidade, tudo de uma vez, não
tem jeito.
Eu vou ter que escolher.
Por isso que, geralmente, a gente vai
falar isso no final, mas empresas muito
grandes, elas trabalham em várias
camadas de cluster.
Uma configuração é para isso, outra
configuração é para isso.
Então, vai ter umas camadas, não é uma
configuração única.
Por isso que o CAP é um pouco mais
complicado de mexer, porque você tem que
pensar até nesse nível.
Olha, para essa entrada de workload
aqui, como é que eu estou esperando?
Esse dado aqui, por exemplo, eu tenho
que replicar ele e tudo mais.
Beleza.
Eu posso replicar o mínimo para eu ter
uma baixa latência?
Se eu replicar duas...
Replicação do A3 ou do A3, acho que três
ou dois, por exemplo.
É o ideal?
Esse cara eu vou dividir ele em regiões
diferentes, eu vou ter brokers em
regiões diferentes para ter garantia que
se um cair, não vai atrapalhar o outro.
Então, a gente começa a levar uma série
de considerações.
Não existe um cálculo para isso, é
baseado realmente em workload, em
necessidade.
Pegou?
No último dia eu falei.
Eu falo mais, tá?
O último dia é a parte de classes.
Pode falar, Ilda.
Você poderia explicar novamente, por
favor, a diferença entre o leader e o
follower lá, por favor?
Posso, claro.
Vamos aqui.
Acho que ele está para baixo.
Leader e follower.
Vamos lá.
O leader é onde a informação que vai ser
gravada e acessada vai estar.
Esse broker, o broker 2, por exemplo.
Ele dá a partição.
Toda vez que eu requisitar para gravar
ou para ler, eu vou no broker 2, que é
onde a informação reside.
Baseado nisso, o que acontece?
Eu botei fator de replicação igual a 3.
Então, além do meu broker 2, está
replicado o dado na 3 e no 1.
Se acontecer alguma coisa com o meu 2,
automaticamente alguém é elegido, porque
eles estão em sync e eu praticamente não
sinto queda.
Não tem nenhum tipo de problema para
aplicação.
Tanto que vai ler como vai produzir.
Isso é uma característica do Kafka.
Então, o leader é onde o dado está
mesmo.
Pensa assim.
O dado que vai ser requisitado vai ser
do leader.
Os outros estão só replicando o dado
para eu ter alta disponibilidade.
Beleza?
Entendeu?
Pegou?
Dá o ok para mim.
Beleza.
João, vou perguntar.
Não, só uma observação até depois, se
vocês quiserem.
Tem uma animação no site do protocolo
Raft que mostra bem legal como é que
funciona essa eleição e como é que
funciona a transmissão desses dados.
Eu estava pesquisando ontem sobre.
Depois, se quiser, eu mando aqui no chat
para abrir.
Manda sim.
Aquilo do Raft é bem interessante,
porque justamente é aquilo que foi feito
o Kraft e que eles colocaram dentro dos
controles para fazer o quórum agora de
nova eleição do Kafka.
É bem legal mesmo.
Vamos mandar aqui.
Perfeito, perfeito.
Mais alguma dúvida, pessoal?
Vamos seguir para o dia 2?
Preparados?
Vamos lá então.
Vamos seguir aqui para a gente poder
começar.
Dia 2, tá?
Dia 2, gente, a gente vai falar de os
dados que estão vindo para o Kafka.
Então, a gente vai falar de esquema de
entrada.
A gente vai falar de formato de arquivo.
A gente vai falar de como que a gente
vai fazer isso.
A gente vai criar aplicações para
interagir em Kafka.
E, gente, eu trabalho com Python.
Eu sou de dados aqui, como grande parte
de vocês.
Não tem ninguém aqui que não seja de
engenharia ou que trabalha com a parte
de dados aqui.
Então, vocês não vão ver uma aplicação
Scala ou Java gigantesca, não.
Vocês vão ver uma aplicação em Python
aqui para a gente trabalhar com as
melhores práticas.
Porque hoje, como eu comentei, o Kafka
aceita vários tipos de linguagens
diferentes, como a gente viu no desenho
lá.
Então, eu vou trabalhar aqui com Python.
Mas as regras primárias que eu vou
mostrar, e vou até mostrar um GitHub
muito legal, que eu vou compartilhar com
vocês dentro do material, que é sobre a
língua de Kafka, vai mostrar para vocês
que, na verdade, é uma abstração.
Eu tenho a biblioteca, na verdade, que
abstrai todas as configurações para
produzir e consumir dados para o Kafka.
Então, a linguagem vira para gosto.
Beleza?
Então, vamos lá.
Primeiramente, vamos dar um zoom aqui.
Formatos de arquivo.
Sim.
Existe formato de arquivo para a gente
trabalhar com o Kafka.
Em que o pior formato para a gente
trabalhar com o Kafka, em gerir dados no
Kafka, é CSV.
Horrível.
Não é legal.
Não é um tipo de formato para trabalhar
com streaming.
Deixar isso bem claro para todos vocês.
A gente tem a opção de XML.
Fica um pouco melhor do que CSV, mas,
mesmo assim, ainda não é interessante.
A gente tem que trabalhar com a parte de
esquema, e o arquivo XSD não é legal de
trabalhar.
Trabalhei e criei outro projeto.
Não é interessante.
Mas não é horrível igual ao CSV, porque
o CSV realmente é complicado de
trabalhar.
E o melhor aqui é JSON.
Só que o formato de arquivo, de novo,
aqui é formato de dados para trabalhar,
seria o JSON em cima desses três aqui.
Beleza?
Só que...
Só que...
O Kafka trabalha com binário.
Isso que é o mais legal.
Se eu estou colocando CSV, XML, JSON
aqui, no final das contas, a transmissão
de dados dentro dele é binário.
Por que eu falei que um é melhor do que
o outro?
É a tradução.
Porque eu vou ter que traduzir esse
binário para um dado legível.
Vou ter que ler esse dado, vou ter que
serializar esse dado e des -serializar
esse dado.
Ou seja, eu vou mandar ele de um
formato, internamente ele vai armazenar
dentro do Kafka como binário, ele vai
ler, eu posso ler de outro leio ou ler
do mesmo formato.
Isso habilita para o Kafka essa
quantidade aqui que a gente tem de
aplicações que podem comunicar ao mesmo
tempo com ele.
No final, para ele, é tudo binário.
Só que...
Geralmente, gente, quando a gente
trabalha com Kafka, eu vou falar do
protobuf, mas o melhor tipo de formato
de open source, para serialização de
dados, é o Avro.
Eu vou dizer para vocês que,
normalmente, quando a gente trabalha com
Kafka, é recomendado até para a própria
comunidade, os criadores, ele foi feito
e pensado em trabalhar com o Avro, que é
nada mais do que um JSON um pouco mais
melhorado.
Então, não é muito diferente do formato
JSON, não.
Porém, ele tem um formato próprio, que é
o Apache Avro.
Um protobuf open source, está suportado
por diferentes linguagens de
programação, em que eu tenho que passar
o esquema.
Beleza?
O protobuf é a linguagem neural da
Google.
Não tem problema nenhum.
Trabalha muito bem com Kafka também.
Ele...
As pessoas comparam ele com o XML, só
que mais rápido, mais simples e menor.
Então, é um XML otimizado e a gente vê
muitos clientes utilizando.
Existe...
Eu sempre falo, sempre que eu ouvir um
protobuf, eu pergunto por que escolheram
esse formato.
Se teve alguma melhoria por parte da
aplicação, alguma facilidade.
Porque normalmente, de novo, ou é JSON
ou é Avro, tá?
Eu recomendo sempre JSON.
Vocês vão ver.
Eu não...
Não vou falar.
Vocês estão falando.
Não vou falar, não, tá?
Existem casos de protobuf...
Eu já tive clientes, tá?
Que tinham ambientes gigantescos com
protobuf.
Mas o Avro, eu ainda assim acho ele até
mais simples de você trabalhar.
Desenvolver o esquema dele, entender o
esquema.
O protobuf tem uns detalhes lá bem
chatos, tá?
Tanto que, para esse treinamento aqui,
eu não tenho, mas eu vou colocar.
Eu estava terminando isso para um
cliente.
Eu vou fazer isso de uma forma de
mockup.
Eu vou criar para vocês um produto de
protobuf para colocar no Kafka Silver,
tá?
Eu já estava testando algumas coisas.
Eu vou deixar lá pronto.
Eu quero deixar...
Eu não quero só entregar.
Eu quero deixar várias facilidades, né?
Como você vai gerar o esquema, um
gerador de esquema, um processo todo de
passo a passo.
Vocês vão ver que o repositório vai
estar bem dividido isso.
Beleza?
Então...
Então, de novo, Kafka, normalmente, a
gente vai pensar em Avra.
Então, aqui, tipos primitivos.
Eu posso embedar documentação dentro do
próprio esquema.
Eu posso evoluir aquele esquema.
Ele é eficiente em questão de
armazenamento e tem compressão.
Então, normalmente, um evento em Avra é
dessa forma, tá?
Então, eu tenho chave, valor, né?
Campo e valor.
E aqui, eu tenho um exemplo de esquema
em Avra.
Tá?
O importante é que, dentro do Kafka, tá?
Eu não tenho obrigação de passar um
esquema na hora da produção.
Vamos falar só de produção aqui, porque
é o tema da aula de hoje.
Quando eu vou produzir os dados, eu não
tenho que especificar um esquema.
Porém, é uma boa prática, tá?
A gente já cria já com esquema,
desenvolver toda a parte de ingestão.
Eu vou explicar ali na parte do Connect,
como é que a gente intera...
Faz a interação junto com o esquema Red
do Connect.
Vocês teriam esse esquema.
Porque, no final das contas, gente, o
dado tem que estar estruturado para a
gente.
Porque, na hora de processar o dado e na
hora de ler o dado, quanto mais você
tiver esquema pronto, mais fácil for,
vocês vão ver que, mais rápido é a sua
entrega.
Até aí, tudo bem?
Pegaram aí?
Avro.
Ok.
Protobuf.
Já vi que vocês tiveram algum problema
com o protobuf, mas ok também.
CSV, por favor, não tentem usar CSV no
Kafka.
Não vão fazer isso.
CSV vai lá para o Lake, vai lá para o
avançamento em batch.
Para streaming, não é ideal, não é
utilizado.
Vão para JSON se não tiver como
trabalhar com Avro.
E, mesmo assim, eu vou explicar para
vocês que, normalmente, o que eu faço?
Se eu não tiver o Avro na ponta, eu vou
criar um tópico em Avro.
Posteriormente, eu vou trabalhar o meu
processamento em cima de Avro dele.
É igual a história do Parquet, né?
Eu vou com o Spark.
Eu trago o dado do jeito que ele é, faço
o Parquet.
Se eu tiver a oportunidade de fazer
Delta, eu já transformo ele em Delta.
E, ali dali em diante, eu tenho uma
melhoria de performance, ganhos ali, por
aí vai.
E aqui também é a mesma coisa, tá?
Gente, vamos para a parte do Schema
REST.
É, ele é...
Exatamente.
Ele é baseado em Java, né?
Então, eu...
O Luan tem uma dita que eu não saio dela
também.
Entre Java e morrer queimado, prefiro
foguinho.
Tentei divulgar o código Java várias
vezes.
Aliás, já divulguei o código Java várias
vezes por causa do Kafka.
Mas, depois, não se dá de nenhum.
O JSON seria pior para fazer o path,
dependendo do nível de alinhamento?
Depende, Pedro.
Mesmo assim, o JSON dentro do Kafka,
ainda você pode fazer um Schema
Enforcement usando o JSON, tá?
Você pode criar o Schema JSON e usar o
que eu vou mostrar agora, que é o Schema
REST.
Então, não seria ruim, tá?
Dá para trabalhar muito bem com ele.
Ele é mais leve, então, acaba que é
rápida a utilização.
Mas, eu recomendo sempre o Avro.
Principalmente, se você tiver muito
nível dentro de nível, tá?
Aí, é interessante você ter um Avro ali.
Mas, eu vou explicar que essa
preocupação que você tem, Pedro,
geralmente, a gente vai suprir ela no
processamento.
E, hoje, pelas tecnologias que a gente
tem de processamento, meio que não faz
tanta diferença.
Eu, na verdade, eu vou ler o dado como
ele é, eu vou trazer tudo e eu vou
processar isso numa velocidade absurda.
Então, porque a quantidade de
processamento é até menor, tá?
O streaming, já estou adiantando para
vocês, a porção que eu vou trabalhar em
processamento é bem menor do que eu vou
trabalhar em batching.
Não vou trabalhar em volumes
gigantescos, também em porções menores.
Mesmo se a complexidade de campo dentro
de campo for alta.
Beleza?
Schema REST, gente, esse cara aqui, para
mim, é...
mão na roda.
O Schema Registry, ele é...
Vou deixar aqui na parte de baixo.
Ele é o quê?
Ele é, na verdade, um repositório de
Schema que trabalha com carros.
Como é que isso funciona?
Quem vai produzir?
Vai mandar uma mensagem com o Schema,
para o Schema Registry.
Olha, esse é o meu Schema.
Vou mostrar para vocês dentro do código,
tá?
Podem ficar tranquilos.
Aqui, ó.
Está aqui o meu Schema e o meu dado vai
para o broker.
Quem está lendo, ele faz um get Schema,
porque ele vai ter informação, o Schema
REST tem informação do tópico.
Quem que é o dono do tópico daquele
Schema?
Ele vai falar assim, olha, esse Schema
que é desse dado aqui, monta para mim.
Então, eu faço um get Schema aqui e eu
trago o dado junto com o Schema.
Isso aqui, gente, bem estruturado, salva
vidas.
Por que eu falo que salva vidas?
Quando você pega um dado JSON, ou
String, ou Byte
Array, e você vai processar esse dado
que não tem um Schema, você tem que, de
novo, você tem que ler tudo, você tem
que esquematizar aquele nível de
computação, porque você vai ter que
esquematizar ele dentro da sua aplicação
para você conseguir trabalhar com o dado
posteriormente.
Você vai ter que, não tem como você
fugir disso.
O que ele te ganha aqui como tempo é,
você já tem o Schema pronto.
Eu vou mostrar, a gente vai fazer
request nas APIs, vamos ver que ele
monta o Schema, tem uns campos e por aí
vai, tá?
Então, isso ajuda muito.
Então, a ideia aqui é eu ter a definição
tanto de valor como de chave, tá?
Isso aqui eu posso ter os dois Schema, o
Key e o Value armazenados dentro do meu
Schema Registry e eu posso ter a
evolução daquele Schema também.
Eu vou ter versões diferentes.
Qual que é o legal disso?
Eu posso ter aplicações, olha que legal,
eu posso ter aplicações que estão vendo
a versão do Schema, é o caso aí que você
comentou no começo da aula.
Natan, eu posso ter uma aplicação que
ele está vendo Schema V1, a versão 1,
tá?
Só que o mesmo tópico, eu vou ter três,
quatro tipos de versões diferentes de
Schema, porque são três aplicações que
estão gravando nele.
E aí, eu pela versão, eu acesso aquele
Schema, aplicação V, a versão 1, praza
que ele dá, acessa e processa que ele
dá.
Qual que é o processo que eu faço?
Ou vai demonstrar a tela, vai processar.
Essa aqui é a grande vantagem dele.
Tem alguma desvantagem em usar o Schema
Raster?
Lilian, eu não vejo, tá?
Não.
É só em questão que você vai ter um
cluster pra gerenciar mais, mas ele é
muito simples.
Ele só faz isso, ele só armazena Schema.
Então, assim, não tem nenhuma
desvantagem.
É só que isso vai crescendo.
E aí, meu amigo, assim, o que acontece?
Você começa com 10 Schemas, depois você
começa com 100 tópicos, cada um tendo 7
versões e vai crescendo.
Então, não é só a questão mesmo da
governança em cima disso, tá?
Mas ele foi feito pra ter só vantagem.
Você não tem desvantagem, não.
Pode ficar bem tranquilo.
Recomendo sempre usar.
Eu sempre uso.
Tanto que quando a gente começou a
trabalhar com o Springzine, ele não
tinha integração com o Schema Raster.
E aí, a gente já olhou também outro tipo
de registrador de Schema, um que chama
Picurio, que eu não vou falar dele aqui.
É nesse momento, mas é um outro open
source, que não é nativamente Kafka, tá?
Esse é...
Na verdade, ele foi criado para o
Postgres, se não me engano.
E aí, é interessante você usar.
O Schema Raster poderia ficar no cluster
de Kafka ou na boa prática?
Eu leio.
Nunca coloque o mesmo componente nível
cluster no mesmo servidor.
Na boa prática, não.
Sempre separado.
Sempre.
Sempre.
O Schema Raster foi feito pra ser um
componente desacoplado do broker.
Ele vai estar separado.
É outro servidor, é uma request
separada, é tudo separado.
Não coloque o mesmo, tá?
O único caso, tá?
Que poderia...
Que a gente tava esperando que o Pulsar
fazia algo parecido.
O Pulsar...
O Pulsar, pra gente, ele é um
concorrente do Kafka, só que não teve
tração.
Por isso que eu até tirei do
treinamento.
Eu falo pouco no final do último dia,
mas, infelizmente, não teve a tração que
a gente queria, esperava.
E ele tinha um componente de function
que rodava no nível do servidor do
broker dele.
Aí seria interessante se o Kafka tivesse
algo parecido.
Você tem uma function de processamento
que roda no topo do broker.
Você simplesmente executa ela e ela é só
uma aplicação.
Seria interessante.
Mas hoje eu considero todos os processos
desacoplados.
Schema Raster e Kafka Connect, mesmo o
Kafka Streams, que é uma aplicação, eu
ainda recomendo ser separado porque tem
a parte de memória, tem a parte de
armazenamento dele, de RocksDB, que eu
vou comentar amanhã.
Então, a recomendação é todos esses
componentes que eu estou mostrando aqui,
eles serem separados.
Nunca um dentro do outro.
Por favor.
Beleza?
Então, tá.
Entender o Schema Raster, ele serve
somente para pegar essa informação aqui,
a definição do Schema, armazenar dentro
dele.
E quando um consumidor quiser ler do
Schema Raster, para ele montar o Schema
da Kitok, ele vai fazer um Get Scheme,
vai pegar o Schema que está aqui e vai
para lá e vai formatar o dado para mim.
Vai serializar o dado.
Beleza?
Trabalhando com Avro é um...
Tem que fazer, tá, gente?
Quando você trabalha com Avro.
É uma...
Não.
Boa prática, não.
É a prática.
Tá?
Até aí, tudo bem?
Estamos todo mundo aí?
Sacamos?
Schema Raster?
Tranquilos?
Beleza?
Estou vendo um monte de joinha.
Ótimo.
Então, tá.
Só que não acaba por aí.
Agora a gente vai entender uma coisa
chamada modo de compatibilidade no
Schema Raster.
Porque o que eu comentei que tem a
questão de evolução de Schema.
Então, quando acontece a evolução de
Schema, tem algumas ordens que têm que
ser seguidas, tá?
Vou deletar um campo ou vou colocar um
campo opcional dentro do meu Schema, tá?
Eu estou trabalhando com Kafka, em
backwards.
Mas, automaticamente, eu tenho que fazer
o
update do consumer primeiro.
Ou seja, chegou lá uma requisição no
pull request para modificar o Schema.
Gente, ó.
Modifica primeiro o consumer, depois
vocês vão lá e modificam o producer, tá?
Aqui está até um desenho com a ordem que
vocês vão levar.
Isso aqui é da documentação da Confluent
mesmo, que é a Confluent que criou o
Schema Raster, tá?
A mesma empresa que criou o Kafka.
Isso aqui é o open source.
Beleza?
Eu tenho o que chama Backwards
Transition, ou seja, eu quero que todas
as versões minhas também aceitem a
deleção, tá?
Aqui é somente o latest Schema e eu vou
ter também todas as versões.
Quer deletar, eu quero ter opcional.
De novo, consumer.
Eu vou mostrar como é que vocês veem
isso, tá?
Eu vou mostrar aqui, eu vou entregar
para vocês o código para vocês verem.
Ah, chegou, vocês podem chegar no
trabalho de vocês no ambiente de
desenvolvimento e vocês poderiam ver.
Ah, eu quero ver como é que está a
compatibilidade desse Schema aqui, tá?
Vocês vão lá e executam o comando, eu
vou mostrar como é que faz e a gente
pega isso lá.
Última versão, tá?
De forward.
Eu estou com o computador tipo forward.
Eu tenho que obrigatoriamente, tá?
Fazer o update do meu producer primeiro.
Lado de cá, producer.
Vou deixar aqui, producer.
Lado de cá, consumer, tá?
Descentado em cima.
Vocês vão perder.
Eu vou adicionar um campo, vou deletar
um campo opcional.
Tem que obrigatar primeiro o producer.
Mesma coisa no forward.
Então, o forward aqui sempre producer
primeiro, tá?
O backwards sempre o consumer primeiro.
O full...
Ah, eu estou com o backwards igual a
full da última versão, tá?
Isso da conta da última versão.
Eu posso mudar qualquer um, não tem
nenhum tipo de regra.
Por padrão, o Schema Registry ele vem
com backwards, tá?
Para você modificar o seu consumer.
Recomendação.
Mantenha o backwards.
Por quê?
O ideal é sempre a gente atualizar quem
vai ler e ter essa ciência que vai ter a
modificação e atualizar quem vai ler.
Se a gente deixa de uma forma que
qualquer um pode modificar, eu já vi
ambientes ficarem extremamente difíceis
de trabalhar por conta disso.
A modificação é muito grande e aí
aparecem campos.
Aparece campo e a aplicação não...
O Schema não quebra.
Então, algumas coisas eu prefiro até
deixar como um problema, né?
Ter uma quebra.
Mas a gente cria uma prática do tipo,
olha, se você está mexendo com Schema,
obrigatoriamente todo mundo tem que ter.
E outra coisa importante.
A partir desse momento, todo mundo que
está consumindo, a gente tem que saber
quem está lá, tá?
E eu vou dar algumas dicas para vocês
identificarem.
Mas, de novo, se não tiver uma regra
interna, é muito mais...
Eu falo de documentação interna do que
do próprio Kafka, tá?
De novo, a gente vai ver isso no dia 4.
É o dia de consumo.
Então, aqui estão todos os tipos de
compatibilidade.
Eu posso ter compatibilidade nenhuma,
onde eu falo, olha, não.
Então, tenta desabilitar.
Qualquer mudança é assim, tá?
Para mudar qualquer coisa dentro do
campo, deletar, adicionar, é
indiferente.
De novo, aqui não recomendo.
Talvez o desenvolvimento seja
interessante.
Vamos ver o Schema Registry, que eu acho
que vocês...
Vamos começar com o Schema Registry
hoje, tá?
Vocês podem ver.
Como o Schema Registry trata esquemas no
banco ou no ciclo?
Isso que é um esquema semi -estruturado.
Vai ter exemplo disso?
Eu vou ter, justamente, um Connect lendo
do MongoDB e trazendo em...
Ou trazendo em JSON, tá?
Mas poderia ser em Álvaro, poderia
colocar...
A gente pode fazer em Álvaro, para você
poder ver.
Não tem diferença para ele.
É um produto que não faz as contas, tá?
Então, ele não vai ler o Schema do banco
que vai montar.
Ele vai pegar a mensagem que você quer,
ele vai interpretar, ele vai falar
assim, opa, esses são os campos e eu vou
jogar aqui.
Aí vai depender de como é que o Connect
é programado.
Por isso que eu vou explicar o produtos
de Connect aqui, para vocês ficarem
antenados.
Então, vamos para o meu Schema Registry
que a gente tem aqui.
Deixa eu dar um zoom para vocês verem.
Eu já vou compartilhar.
Então, vou botar 16.
Vocês me falam...
Acho que eu vou aumentar mais um
pouquinho antes de compartilhar aqui.
Eu já compartilho tudo.
Vamos ver se...
Vamos compartilhar o meu PyCharm.
Vamos lá, gente.
Então, uma limpada aqui que eu estava
testando mais cedo, porque eu não sou
bobo.
Então, aqui, ó.
Vou fazer um call dentro do meu Schema
Registry.
Isso aqui é uma IP do meu Schema
Registry, tá?
Como é que eu sei?
Eu vou lá no meu cluster.
Vou falar assim, olha.
Qual que é o IP externo do meu Schema
Registry?
Aqui é o Schema Reloading Balancer.
Externo é o IP.
Esse cara aqui, tá?
E vocês, como é um IP externo, vocês
podem rodar esse comando aqui durante a
aula, até mesmo pelo que esse cluster
vai ficar ligado somente nesse processo.
O que eu vou pedir é não façam nenhum
push, nenhum push para atrapalhar o
nosso treinamento, tá?
Mas se vocês quiserem fazer o get, eu
vou mandar depois aqui, vocês podem
testar para vocês verem como é que é.
Vou até testar aqui para vocês poderem
ver na tela, tá?
De vocês.
É só legal ter um pouco de interação.
Então, aqui, olha.
O que eu fiz aqui, tá?
Eu vou deixar isso para vocês verem.
Eu fiz o config onde ele fala, olha,
Compatible Level Backwards, porque é o
mesmo padrão.
Beleza.
Eu quero pegar os meus Schemas.
Então, eu vou fazer assim, olha.
Traz para mim os objetos, os Subjects,
que estão dentro do meu Schema Registry.
Então, eu vou vir aqui e vou rodar e eu
tenho esses Schemas.
Value, sempre que você for, essa
automática eu dei, tá?
Se você mandar mensagem de chave valor,
ele vai separar, olha, o Value na frente
e o Key.
Ou seja, o Schema de um Schema de outro.
Beleza?
Coloquei aqui ótimo, para vocês poderem
comparar posteriormente.
Vou pegar esse caso aqui e vou ver o que
está dentro dele.
Na verdade, eu vou ver qual é o nível de
compatibilidade desse, porque eu posso
ter níveis de compatibilidade
diferentes, tá?
Em Schema.
Eu posso ter o padrão para todos.
Se eu criei em um específico, eu falo,
ou eu posso chegar lá e falar assim,
olha, esse Schema agora, ele é Full.
Ou esse Schema, ele é Forward, tá?
Eu quero que seja dessa forma.
Então aqui, como eu não mudei, por que
você está dando um
erro?
Onde é que o senhor está dando?
Aqui funcionou.
Not Found.
Schema Not Found.
Aqui, vamos ver.
Você está aqui, joia.
Opa.
Entrou.
Difícil, hein?
O que é que ele está dando?
Depois eu vou olhar o que está dando
mensagem, se mudou de forma.
Mas pode dar não.
Aqui eu tenho os IDs.
Porque cada Schema, ele tem...
Olha, eu estou sem acesso.
Nossa, o Plus está ok.
Tá.
Aí você testa.
Está tudo bonitinho aqui, olha.
Aí você testa.
E aí acontece isso.
Na hora de testar mesmo, é o demo da
demo.
Sempre...
Não estou conseguindo...
Ah, não.
Não, não estou conseguindo chegar lá.
Por quê?
Pimenta do céu.
Aqui, olha.
Testei e estava funcionando.
Deixa eu ver outro teste aqui.
Não, esse aqui é o último mesmo que eu
tinha
feito.
Gente, alguém me derrubou aí.
Me derruba não, hein?
Pelo amor de Deus.
Eu fiz vários testes.
Mais cedo aqui, olha.
Aqui está funcionando.
Subjects.
E mudou.
Na hora do intervalo, eu dou uma olhada
no que está acontecendo aqui.
Vamos perder tempo.
Por algum motivo ele não está
respondendo aqui.
Pode ser alguma coisa lá no Digital
Ocean, tá?
Mas eu tinha testado todos aqui e estava
funcionando.
Tanto que até coloquei o output aqui.
Está até aqui para a gente poder ver.
Quando eu faço esse comando aqui,
Schemes ID, ele vai trazer todos os meus
esquemas, os meus objetos, versão, o ID
e o esquema dele.
Está vendo?
Aqui tem toda a parte.
Aqui tudo gerado.
Quando vocês estão vendo aqui, olha.
Estou com o debizing aqui.
Vou mostrar para vocês hoje.
Então, isso aqui é um connect, por
exemplo.
Tem todas as informações aqui de
connect.
Vamos pegar um outro aqui.
Acho que eu não tenho de mão.
A gente vai subir ele na hora.
Isso aqui também.
Não, não.
Isso aqui é connect.
Aqui é a aplicação.
Isso eu queria mostrar.
Aqui, olha.
Type, record name, user, a namespace.
De novo, eu queria mostrar o esquema
para vocês.
Os campos do meu esquema.
ID, string.
Tem todos aqui, tá?
As minhas informações.
Doc, eu poderia documentar o meu
esquema, as minhas colunas aqui dentro.
Eu não documentei.
Mas está aqui.
Dentro do repositório, tem esses aqui,
tá?
Esses são os esquemas que eu criei em
JSON.
Então, esse é o esquema Avro.
Na verdade, quando eu for produzir
dados, ele vai procurar essa pasta aqui.
Esse arquivo.
E vai esquematizar para mim.
Vai mandar esse esquema aqui para o
esquema S.
Vou mostrar isso na parte de producer.
Então, aqui está um exemplo de
estrutura.
Estrutura de esquema Avro.
E aqui, está vendo?
Eu até coloquei aqui algumas
informações.
Aqui a documentação, tá vendo?
Tem os docs aqui.
Beleza?
Aqui é só por questão de documentação,
tá gente?
Isso aqui não tem nada de...
E é uma...
Eu não diria que é uma melhor prática.
Mas é uma boa prática a gente documentar
para saber para que aquela coluna
funciona.
Para ver pelo esquema e tal.
Não coloca coisas muito grandes.
Coloca o sentido, o objetivo.
Sejam objetivos.
Mas aqui é uma...
É uma prática boa para poder fazer.
Beleza?
Então, vamos seguir a aula.
Porque hoje, não coisa...
Não vai dar nada.
Nem chegamos nessa parte simples.
Esquema registro.
Pegaram?
Todo mundo ok?
Então, ok, por favor.
Beleza.
Joinha.
Adoro joinha.
Deixa eu só acertar.
Agora fiquei curioso.
Depois eu vou ver.
Por que esse cara que eu testei o dia
todo foi falhar
agora?
Não, mas tem como você trazer todos.
Aqui está passando o ID 1.
Está passando o específico.
E se você passa tudo, ela vai pegar
tudo.
Vai responder tudo.
Não entendi porque eu não tinha testado.
Mas sim.
Se você colocasse um ID.
Aí você fala assim.
Traça -me o ID 1.
Ele vai trazer o primeiro.
Você vai trazer o 2.
O 3.
Você vai trazer especificamente o que
você quer.
Queria mostrar.
Mas acontece.
Demo é assim mesmo.
Ambiente de teste.
É assim mesmo.
Mas foram todos testados antes.
Então, você está tudo bem tranquilo.
Não tem problema.
Vamos para a fritação agora.
Vamos entender como que um producer
funciona.
Comentei esse cara.
Falei.
Vamos falar um pouquinho da producer
API.
Primeiramente.
Producer API.
Primeiro batch.
Autorização que realmente leva.
Geralmente a Java escala.
Depois tem os mais populares.
Tem mais C, C Sharp e Python Go.
E eu estou vendo muita coisa de Rust
agora.
Importante que a Liberty Kafka.
Ela é uma biblioteca de implementação de
C++.
Que é protocolo Kafka.
Aquele que ela funciona.
Em vez.
Olha que legal.
O primeiro client é Java escala.
Só que.
Criaram uma biblioteca separada.
Chama Liberty Kafka.
Que ela tem todas as configurações.
Base para todas as linguagens.
Então, todas as linguagens.
Na verdade.
Elas usam.
Por debaixo dos panos.
Fora Java escala.
Está mais Python.
C Sharp.
Elas usam a Liberty Kafka.
Como a implementação.
Para poder usar o protocolo de C Sharp.
Por isso que.
O pessoal fez.
Em C.
Em C++.
Por ser mais rápido.
Por não ter necessidade de usar JVM.
Então, a gente tem diversas.
Linguagens diferentes.
Eu tenho aqui.
Um bind das linguagens.
Que vocês podem depois consultar.
De novo.
Você tem desde.
Node .js.
PHP.
De novo.
Python.
Python.
Tem duas.
Duas linguagens.
Tem até a Kafka.
Python.
Também.
Deixa eu te colocar ela aqui.
Rust.
Shell.
Você pode trabalhar com Shell.
Swift.
Por aí vai.
Então.
Bind de linguagem.
É o que mais tem aqui.
Na Liberty Kafka.
Eu até coloquei ela aqui.
Para vocês.
O link.
Está aqui.
No repositório.
Também.
Beleza.
A gente vai ver.
Esse cara aqui.
Então.
Aqui eu uso bastante.
Uso bastante.
O que eu falo.
Para quem tem alguma dúvida.
Ah.
Eu quero saber.
Uma configuração.
Específica.
Aqui.
Eu venho aqui.
Configuration.
E aqui.
Eu tenho.
C.
Ou.
P.
Consumer.
Ou.
Producer.
Asterisco.
Vale para as duas.
Então.
Eu vou vendo.
Quais.
Que são.
As configurações.
Que eu posso.
Essa configuração.
Que eu colocar.
Aqui.
No meu.
Producer.
Vai.
Funcionar.
Como é que eu vou saber.
Eu estou trabalhando.
Com ser chato.
Agora.
Trabalhando.
Com o pai.
Então.
Como é que eu vou saber.
Qual para qual.
Tá aqui.
Tá.
E o default.
Para elas.
Porque.
De novo.
Elas usam.
A libetcafe.
Como.
A nossa.
Biblioteca.
Base.
Dependente.
De qual linguagem.
Você está.
Se for.
Java.
Escala.
Né.
Aí.
Já muda um pouco.
Porque.
De novo.
São as primárias.
Mas.
Eu não vim novo.
Em Java.
Escala.
Então.
Fico.
Nesse cara.
Aqui.
Beleza.
Aqui.
Eu recomendo.
Para quem.
Trabalha.
Com.
Python.
A.
Confluent.
Python.
É.
Uma linguagem.
Da.
Confluent.
Você.
Vai.
Poder.
Usar.
Para.
Interagir.
Com.
O protocolo.
Kafka.
É.
Extremamente.
A.
Confluent.
Frisa.
Era.
Tanto.
Para.
Kafka.
Open Source.
Conto.
Para.
Confluent.
Cloud.
Contante.
Plataforma.
É.
Um padrão.
E.
Ela.
Bem.
Simples.
É.
Evolui.
Constantemente.
E.
Eu.
Gosto.
Bastante.
De.
Usar.
Ela.
Comecei.
A.
Usar.
Kafka.
Python.
Mas.
Esse.
Aqui.
Tem.
Uma.
Demonstração.
Vou.
Mostrar.
Um.
Pouco.
Mais.
Beleza.
Vamos.
Entender.
Como.
É.
Que.
Cara.
Funciona.
E.
Isso.
Aqui.
Gente.
Tem.
Uma.
Mágica.
Aqui.
Que.
Depois.
Que.
Você.
Entende.
Eu.
Começo.
A.
Perguntar.
Algumas.
Coisas.
Para.
Clientes.
Geralmente.
E.
E.
Cara.
Como.
É.
Possível.
Que.
É.
Assim.
Vamos.
Entender.
Como.
É.
Que.
Eu.
Produzo.
Um.
Dado.
Quando.
Eu.
Mando.
Um.
Dado.
Eu.
Tô.
Mandando.
Mensagem.
Estou.
Mandando.
Mensagem.
Ele.
Vai.
Fazer.
Com.
O.
Ex.
O.
Ex.
Ele.
É.
Semântica.
De.
Garantia.
De.
Mensagem.
De.
Mensagem.
Ele.
Vai.
Por.
De.
For.
Um.
O.
Ex.
Ele.
Vai.
Mandar.
Meta.
Dado.
Que.
Se.
Você.
Tiver.
Alguma.
Falha.
Vai.
No.
Meta.
Dado.
Aqui.
A gente.
Vai.
Ver.
Uma.
Prática.
Chamada.
Callback.
Que.
Se.
Eu.
Não.
Tiver.
É.
Callback.
Configurado.
Quando.
Meta.
Dado.
Volta.
Com.
Erro.
Você.
Nem.
Consegue.
Ver.
Com.
Ele.
E aí.
Muitas.
Vezes.
Eu.
Cheguei.
Cara.
Você.
Tem.
Qual.
Que.
Função.
De.
Callback.
Não.
Na.
Prática.
É.
A.
Prática.
Também.
Quando.
Eu.
Falo.
Abro.
Esse.
Cal.
Back.
Então.
Função.
De.
Como.
Mostrar.
Uma.
Prática.
Ela.
Tem.
Que.
Ter.
Porque.
Tudo.
Isso.
Acontece.
Eu.
Nem.
Mandei.
A.
Mensagem.
Eu.
Mando.
Quero.
Mensagem.
Ele.
Manda.
Ele.
Manda.
O.
Fil.
Meta.
Data.
Isso.
É.
A.
Prova.
Certificação.
Quando.
Ele.
Volta.
Aqui.
Se.
Você.
Não.
Tiver.
Com.
Back.
Configurado.
Ele.
Praticamente.
Vai.
Te.
Mandar.
Sem.
Erro.
Você.
Falou.
Foi.
O.
Aconteceu.
Não.
Dá.
Para.
Saber.
Então.
O.
Líder.
Recebe.
Quando.
Ele.
Recebe.
Ele.
Manda.
Para.
Os.
Fóruns.
Aqui.
Lembra.
Os.
Fóruns.
Aqui.
Olha.
Vai.
Começar.
Falar.
O.
Gravou.
Gravou.
Gravou.
Tá.
E.
A.
Gente.
Vai.
Entrar.
Agora.
Olha.
Que.
Legal.
Isso.
Aqui.
Gente.
Isso.
Aqui.
Muito.
Legal.
Como.
Que.
Funciona.
Um.
Produzir.
Quando.
Eu.
Mando.
Olha.
Que.
Negócio.
Legal.
Que.
Negócio.
Interessante.
Eu.
Tenho.
A.
Mensagem.
Eu.
Vou.
Se.
Pegar.
Em.
Baixa.
Meio.
Cara.
Esse.
Aqui.
É.
Um.
Jason.
Eu.
Vou.
Mandar.
Qual.
O.
Serializador.
Que.
Vou.
Trabalhar.
Com.
Ela.
Lembra.
Da.
Partição.
Eu.
Tenho.
Um.
Componente.
Modo.
Partitioner.
Que.
Falar.
Assim.
Esse.
Cara.
Aqui.
Ele.
Tem.
Chave.
Não.
Tem.
Se.
Não.
Tiver.
Eu.
Fazer.
Hoje.
Log.
Ou.
Seja.
Vou.
Colocar.
Na.
Partição.
O.
Bet.
Zero.
O.
Bet.
Um.
Depois.
Vou.
Passar.
Aqui.
Bet.
Zero.
Um.
Pedaço.
Aqui.
Um.
Pedaço.
Aqui.
Ah.
Não.
Ele.
Tem.
Uma.
Chave.
Essa.
Chave.
Já.
Foi.
Gravada.
Foi.
Tá.
Na.
Partição.
Um.
Então.
Automaticamente.
Vai.
Gravar.
Aqui.
Dentro.
Tem.
Tem.
Um.
Componente.
Mais.
Partition.
Para.
Isso.
Em.
Caso.
De.
Falha.
De.
Procuração.
Deu.
Falha.
No.
Meio.
Do.
Caminho.
Seja.
Para.
Qual.
Motivo.
Que.
Fora.
Disponíveis.
Não.
Atende.
Por.
Exemplo.
Acontece.
Muito.
Isso.
Que.
O.
É.
O.
Not.
Enough.
Replicas.
Disponíveis.
Ele.
Volta.
Se.
A.
Falha.
Tem.
Retrai.
Configurado.
Tem.
De novo.
Tem.
Traga.
De novo.
Tem.
Tem.
Tem.
Uma.
Replicação.
De.
Retrai.
Que.
Eu.
Mostrar.
Para.
Vocês.
Retrai.
Baseado.
Na.
Quantidade.
Que.
Você.
Tiver.
Só.
Tem.
Então.
Muito.
Cuidado.
Porque.
Existe.
Configurações.
Em.
Que.
O.
Retrai.
Ele.
Mais.
Bagunça.
Se.
A.
Pessoa.
Não.
Entender.
O.
Retrai.
Ele.
Acaba.
Atrapalhando.
Um.
Pouco.
Se.
Você.
Ou.
Você.
Acha.
Que.
É.
Problema.
Em.
Na.
Região.
Comportamento.
Normal.
Se.
Você.
Não.
Configurar.
Mais.
Coisa.
É.
Client.
Não.
É.
O.
Server.
Então.
Várias.
Configurações.
Ex.
Por.
Exemplo.
Eu.
Vou.
Falar.
O.
Tipo.
Que.
Vai.
Ser.
Quem.
Vai.
Mandar.
Não.
Vai.
Ser.
O.
Server.
Que.
Vai.
Perguntar.
É.
O.
Client.
Que.
Manda.
Se.
Eu.
Não.
Falei.
Nada.
Em.
Baixa.
Para.
Ele.
Poder.
Ser.
Carregado.
No.
Carro.
Só.
Que.
Estou.
Mandando.
Um.
Jason.
Estou.
Mandando.
Um.
Lá.
O.
Partitioner.
Aqui.
Fala.
Assim.
Esse.
Cara.
Tem.
Chave.
Ou.
Não.
Para.
Escolher.
A.
Estratégia.
Particionamento.
Se.
Tiver.
A.
Chave.
Eu.
Já.
Se.
Se.
Essa.
Chave.
Já.
Existir.
Eu.
Vou.
Pro.
Mesmo.
A.
Partição.
Eu.
Só.
Fazer.
Uma.
Partição.
Se.
Ele.
Vai.
Fazer.
O.
Seja.
Esse.
Cara.
Quem.
Responder.
Primeiro.
Eu.
Coloco.
Esse.
Aqui.
Ou.
Esse.
Aqui.
Ou.
Esse.
Aqui.
Então.
Vai.
Pro.
Mesmo.
Vai.
Sempre.
Vai.
Embaralhado.
Não tem.
Chapo.
Me.
Da.
Ok.
Por.
Favor.
Todo.
Mundo.
To.
Lá.
Em.
O.
seas.
Agora.
Se.
Vai.
Ver.
O.
Eu.
Falei.
Rapidamente.
Que.
Tá.
Ótimo.
mas é bom, vocês têm essa dúvida, por
quê?
porque agora a gente vai falar as
configurações depois eu falo do X,
porque o X é complicado não entendi por
que tem dois
tópicos a mensagem pode ir para mais de
um tópico ou como assim, não, aqui o
Gabriel aqui é só uma extração, engine
cluster tem um tópico A e B, mas não
necessariamente eu posso mandar para
mais de um tópico se eu tivesse
configurado dentro do meu da minha
aplicação, né posso fazer um loop para
mandar para tópico diferente, mas o
ideal é ser sempre de um para um, eu
gosto de fazer de um para um mas aqui é
só extração não tem nada a ver não, aqui
eu vou estar mandando para um tópico A,
não eu estou mandando para um tópico A e
tópico B o partícipe na hora de conexão
recebe quais configurações do tópico
para saber onde enviar a mensagem,
perfeito João chave lembra aqui?
chave tem chave?
tem baseado na chave ele tem um origin
dele próprio que ele vai saber para ser
se for gravado em algum momento, nem dos
tópicos de sistema do CAF ele vai falar
assim, olha, esse tópico aqui já foi,
essa chave já foi gravada na partição 0
faz o apêndice na partição 0 já foi
gravada na partição 1 e aí é quem
responder primeiro que vai ser o
primeiro vai ser elegível, tá, se não
tiver não tem ninguém, é a primeira
chave a primeira que essa chave vai
entrar em uma partição quem responder
primeiro leva a partir daí vai levar
mais da vida sacou?
ter um componente dentro do broker
separado tá tá , dentro do algoritmo do
CAF então tá, vamos entender então as
configurações principais aqui, tá
configuração principal vou dar até um
zoom aqui vou até fazer aqui, ó pra
ficar melhor pra vocês poderem
ver configuração principal bootstrap
server eu tenho que ter um bootstrap
server eu tenho, é o que eu coloquei
como principal tá, mas de novo, não é
obrigatório se você não colocar o
próprio CAF que vai gerar um um um , um
hash pra você do client ID recomendo
colocar o client ID o client ID pra
identificar a instância que tá sendo,
que tá requisitando aqui da dama da
aplicação o serializador da chave e
valor beleza?
além disso, né eu tenho que falar o nome
do top que eu quero carregar tá, essas
são as configurações padrão ou seja pra
me mandar isso aqui eu tenho que ter o
nome do top e essas configurações
iniciais aqui tá, basicamente é isso que
eu preciso eu posso utilizar em byte
array eu posso fazer em byte eu posso
fazer em string long tem vários tipos de
dados que eu posso estar trabalhando ou
fazer até um custom serializer eu posso
ter um serializador customizado nesses
cinco anos eu nunca peguei um
serializador customizado não tá, só pra
você saber eu sei que tem eu já vi casos
já conversei só com o CAF bastante
pessoas que tinham mas eu nunca vi
geralmente o pessoal usa em byte array
ou usa os padrões beleza?
então eu vou fazer um serializador
customizado eu vou ler o dado eu vou
produzir aquele dado serializado dentro
do meu cluster e vai estar armazenado lá
em byte tá, em binário desculpa beleza?
até aí configurações batem a gente vai
ver isso na prática tá, de novo vou
mostrar isso na prática só que aqui
começa a ficar legal
quando eu tenho métodos de envio de
mensagem e aqui eu vou explicar agora o
porquê do X tá mas vamos lá quando eu
vou mandar mensagem eu posso fazer uma
coisa que chama file forget ou seja isso
também está na prova certificação na
hora que eu enviar fazer o send eu envio
e nem espero nada eu só mando o próximo
eu não eu não espero eu só fico mandando
tá isso é o método utilizado para quando
eu aceito que eu vou ter perda de
mensagem porque o meu cliente só vai
disparar ele não vai esperar nada ele só
vai disparar a mensagem eu posso fazer
de forma assíncrona assíncrona desculpa
síncrono eu mando quando ele retornar o
metadado e aí eu executo batch a batch
tá aí eu vou ter que fazer ele síncrono
ao meu envio de novo porque eu estou na
parte do envio só beleza aí eu sou só
enviando e eu posso fazer o assíncrono
que eu mando de forma assíncrona e ele
triga uma resposta se o meu callback for
acionado então tive um problema por
qualquer motivo a função de callback
entrou aí ele entrega a resposta mas
senão ele vai só enviar enviar e aí vem
a parte do X o X gente ele é separado em
0 1 ou at least mando a mensagem o
broker recebeu ele não me retorna ok eu
já mando o próximo batch tá então aqui é
nível aqui é a comunicação do client da
API de producer aqui com a API de
producer aqui dentro do broker tá ele
vai falar assim olha envia pra cá e não
espera beleza X igual a 0 ele vai
mostrar isso na aplicação o padrão X
isso aqui é na gravação tá aqui ele fala
assim gravou não espera gravar nele no
líder aqui é o líder tá gente vamos
pegar que isso aqui é o líder não espera
ele gravar nele já manda o próximo batch
o padrão que é o X igual a 1 mando pro
líder o líder fala gravei em mim tá
gravado ele volta a resposta de gravando
dá ok pode mandar o próximo e ele
executa aqui já não é gente o o metadado
não tá aqui já tá dando ok que ele
gravou a partir disso se acontecer um
problema aqui no meio do caminho ele
pode é duplicado porque ele pode mandar
mais de uma vez o mesmo dado aqui ele
gravou por algum motivo ele acha que
esse cara que não recebeu mandou duas
vezes então não tem um garantia aqui
aqui perda que não tem garantia de
resposta aqui que não tem garantia de
resposta das réplicas dos followers
então eu posso dar duplicado aqui e esse
é o padrão cáfrica tá zero é o padrão
lembrando que se eu tô no nível zero
desculpa o maior padrão o zero é quando
eu quero o high input é o que gente eu
tô na IoT eu tenho que receber dado o
tempo inteiro e não me importa se eu
perder dado eu vou usar o zero que eu
tenho que ter um throughput alto eu
aceito a minha perda porque eu vou
ganhar na velocidade aqui eu quero ter
um mínimo de garantia olha o dado pode
duplicar mas eu sei que tá lá pelo menos
e eu vou continuar tendo um alto
throughput não tão alto como zero mas eu
vou ter alto só que aí em 2017 se não
foi de um dia pro outro o cáfrica ele
chegou na maior mais alta garantia de
entrega que é o exactly once como é que
ele funciona tá o exactly once é envia
pro líder todas as réplicas elas
garantem que tá gravado e aí eu mando o
próximo temos algumas vantagens desse
cara aqui tá por exemplo pelo fato de eu
ter essa garantia de gravação é uma
coisa eu não tenho um dado duplicado eu
não tenho perda porque eu tenho que me
mandar outra coisa importante eu tenho
uma garantia mínima na hora do envio de
organização na ordenação na ordenação
interna tá mas na hora do envio então
uma mensagem que é enviada aqui ela vai
ser enviada ordenada quer dizer que ela
vai ser gravada ordenada tá eu só
consigo garantir ordenação de mensagem
se eu tiver uma partição uma partição x
igual a all vai estar sempre ordenada o
que eu mandar vai ser aquela ordem exata
que tá lá dentro pra garantir a
ordenação do envio na gravação também
então o all é o mais alto nível que tem
tá então aqui de novo um como eu
comentei ele é o padrão mando pro líder
né que o líder tá aqui líder me mandou
mando o próximo não espera as réplicas
gravarem é que eu espero qual que é o
problema aqui lentidão se eu tiver um
cluster muito grande eu vou ter que
esperar todas as minhas réplicas ou seja
eu tenho réplica igual a 10 vamos supor
tá eu tenho réplica igual a 10 aqui eu
tenho 15 nós eu vou ter que esperar os 9
os 10 né o líder gravou os outros 9
gravarem me responderem todo mundo que
gravou pra poder seguir o próximo patch
então eu perco muito tempo no all aqui
mas eu tenho uma garantia extremamente
alta por isso eu comentei que o cálculo
vai começar a ficar vai ficar claro olha
o fator de replicação mais a
configuração dos producers vão ditar
como é que o seu ambiente vai estar
comportando se eu tenho 3 réplicas aqui
apenas normalmente tá não vai ser tão
demorado vai ser rápido eu vou estar ali
na casa de milissegundos talvez próximo
de segundo tá milissegundo mas depende
da latência de rede entre eles se for
dentro do kubernetes isso aí eu estou
dentro da mesma máquina geralmente então
tá na hora então aí eu tenho baixa
latência Lilian infelizmente nenhum dos
dois a configuração de X é nível
producer infelizmente nem top nem
servidor é producer ou seja quem criou a
aplicação ela já tem que ter
reconhecimento de cara para poder fazer
isso você conseguiria nos passar no caso
de uso onde a perda de IoT é aceita eu
ler por exemplo IoT estou mandando
milhares de eventos de máquina e eu
tenho que ter um throughput muito alto
bilhares ou bilhões de eventos eu aceito
perder porque eu posso ter um zero
quando tem um erro mesmo é contínuo o
erro então eu aceito a perda geralmente
é caso de IoT o pessoal usa o cliente
grande lá fora ele usa clusters e
clusters disso aqui beleza eu vou seguir
depois eu vou
mostrar a aplicação como todo até o
final vamos seguir até o final hoje eu
vou dar os 10 minutos de pausa lá para
as 9 horas e a gente na verdade eu vou
fazer a pausa quando a gente mudar para
connect então eu vou mostrar a aplicação
eu vou mostrar cada pedaço da aplicação
para vocês para que vocês pensarem uma
coisa que eu quero trazer para vocês
aqui é tentem pensar também não só usar
connect na parte da data tenta criar
APIs mesmo eu recomendo fortemente
trabalharem com Python com APIs para
comunicar com Kafka às vezes a
flexibilidade é tão grande que compensa
não para tudo comunicação com API com
API faz sentido alguns casos fazem
sentido mas a gente vai ver que a
flexibilidade aqui é muito maior quanto
se desenvolve mas de novo a
flexibilidade é maior a complexidade
também aumenta comparado com isso também
beleza?
então beleza schema registry como eu
comentei produtor irmão do valor schema
version enviado aqui e aqui eu tenho uma
configuração básica que eu passo a URL
do schema registry o tipo avro que eu
vou usar aqui para vocês eu vou comentar
de algumas propriedades como linger e
back side eu vou chegar lá para vocês
poderem entender um pouco mais tá?
e é esse linger eu já vou adiantar
prestem atenção e perguntem se não
entenderam tá?
essa propriedade cai em prova também tá?
geralmente tá?
as configurações que eu recomendo
utilizar id.
se eu quiser usar o x igual a all que
geralmente eu uso tá?
id .enable eu vou explicar esse cara
aqui tá?
é isso o id .enable equals to true e x
igual a all que garantem o exact once a
month que eu comentei que é o que?
não tem um pdj não tem duplicidade e eu
não envio a mensagem ordenar tá?
esses dois configurações juntas eu não
posso dar o x igual a all esse cara não
tá habilitado já me tiver como falso tá?
maxing write request eu vou explicar
também quando eu mando um dado quando eu
mando uma mensagem um grupo de mensagens
eu posso mandar várias ao mesmo tempo
tá?
eu posso falar assim olha aumenta 5 e eu
mando eu vou mandar 5 requisições o que
que isso é?
isso é bom para throughput geralmente eu
coloco isso no 0 e 1 onde eu mando
várias mas o x é bom a gente colocar um
porque se der algum problema eu já não
envio a outra porque eu geralmente não
vou esperar o retorno quando tem maxing
write request maior do que 1 mas eu vou
explicar também a questão de ordenação
clash id o tamanho do batch que eu vou
enviar depende do workload não tem uma
regra mágica eu gosto de ver o workload
entender de novo o caso que é muito
disso da gente quem que fala?
eu vou falar com vocês que tem uma regra
específica como vocês vão olhar em
ambientes mesmo é muito de teste
validação porque os ambientes hoje são
muito heterogêneos um ambiente é
exatamente igual ao outro então tem que
tomar cuidado e o x de novo se eu não
passar esse aqui é 1 se eu não passar
esse aqui é falso e lá dentro como eu
comentei aqui olha que legal aqui eu
tenho os defaults então se eu for em
linear eu vou explicar o linear daqui a
pouco tá?
ele é 900 milissegundos tá?
o padrão dele aqui é esse aqui que é o
padrão deixa eu conferir é 0 default 5 5
milissegundos tá?
então vamos entender um pouco mais de
novo eu gosto de bater bem nessa tecla
aqui pra ficar bem claro o x tá?
at most mandei a mensagem eu posso ter
perca aqui ó no meio do caminho e é
normal é aceitável tá?
de novo aí eu tiro enviei de 1 a 8
chegou 1, 3, 4, 5, 6, 8 normal tá?
tô com x at most eu tenho um throughput
alto eu tenho um throughput de 10
milissegundos eu tenho um throughput de
20 milissegundos tá?
faz sentido quando eu quero ter um
throughput extremamente baixo que o
cápita chega até 10 milissegundos faz
sentido at least tá?
eu tenho posso ter duplicado o dado vem
em ele pode ser duplicado por uma vez
que a réplica falou peraí manda me mudar
de novo que não sei se eu gravei pode
mandar duas vezes então pode acontecer
disso não é algo incomum de acontecer e
esse é o padrão do cápita então esse
aqui é o
default beleza?
vem 1, 2, 2 3, 4, 5, 6, 6, 7, 8 né?
x at most você manda se quiser enviei de
1 a 8 vai chegar de 1 a 8 na ordem de
1 a 8 vai chegar de 1 a 8 acho que eu já
voltei
vocês ouviram até qual?
vocês ouviram até a parte do x at
semântico daqui eu expliquei vocês
pegaram?
at least tá at least beleza então vou
explicar o x at semântico de novo o x at
semântico é mandei de 1 a 8 ele vai
chegar de 1 a 8 sem perda sem duplicada
e na ordem tinha que chegar no envio tá?
muito importante muito importante
beleza?
e então a gente vai ter que habilitar
retry também de novo retry aqui de novo
como eu comentei retry ele tem ele
funciona bem quando tem as configurações
corretas então tem que pensar também em
qual x que eu vou estar usando para
utilizar o retry até aí tudo bem?
tamo tranquilo?
event ordering lembra que eu comentei do
do max and fly
request?
no at least once ele só duplica nos
follows no leader também no leader
dependendo da no leader o que acontece
quando os followers começarem a replicar
e sincronizar eles vão sincronizar
também o dado com o leader e vai mudar a
mais ele nunca vai deletar ele vai
passar opa tem esse dado aqui ó append
ele vai sincronizar o que ele vai fazer?
ele vai sincronizar e mandar quando eles
deram o sync entre eles leaders e
followers opa tem um dado aqui o leader
não tem não tem sincroniza porque na
verdade o leader também é uma réplica
então quando a gente viu lá no sync ele
vai contar o leader como uma réplica
então sim ele vai o dado vai também para
o leader por isso que isso pode
acontecer beleza ordenação de dados tá
se eu estou mandando com marks and fly
requests tá igual a maior do que um eu
vou mandar aqui três por exemplo ele vai
mandar os três se um falhou ele vai
fazer o seguinte ele vai mandar falhou
voltou mais um e o três gravou retry
então retorno dois não tem ordenação se
eu estou com marks and fly requests
igual a um aqui ó marks and fly requests
igual a um eu tenho um retry maior se
ele for fazer retry até conseguir subir
né eu coloquei aqui um milhão que vai
gerar e o x igual ele vai um vai ele vai
gravar um o dois não gravou erro de
networking seja qual for ele vai fazer o
retry e ele não vai fazer o três
encontro algo bad do dois não gravou não
dá sucesso então ele vai continuar a
ordenação não vai ter reordering ou seja
vai continuar a ordenação do envio o
três não entra enquanto o dois não foi
executado não foi gravado tá então essa
é uma boa prática poder fazer beleza e
aqui meus amigos a gente entra nesse
cara aqui que eu queria mostrar somente
esse cara aqui de todas as configurações
até agora vou até mudar vocês poderiam
ver fica mais claro essa é uma
configuração que eu considero
extremamente importante por que eu falo
extremamente importante o linger tá
porque pouco se fala dele pouco se
entende na verdade dita muita coisa o
linger é a latência entre um batch que
eu envio para o cafo e outro então o
linger igual a zero eu vou mandar a
gente para o evento então evento evento
mas isso não contaram para vocês eu
estou contando agora o cáfica ele
funciona melhor quando você trabalha com
batch nem que seja micro batch por que
porque cada evento é uma request se eu
mandar evento a evento se eu tiver 10
mil eventos eu vou ter 10 mil requests
se eu tiver o linger por exemplo igual a
100 milissegundos 500 milissegundos
vamos botar que seja milissegundos mas
que eu tenho um tempo um espaçamento de
eventos mais com batch size eu vou
mandar mensagens em batchs mas vou
mandar em batchs ainda ser melhor porque
não vou bater tanto no cluster então em
grandes casos por exemplo meu cáfica
está sendo um darel de coisa e começou a
cair mas está colocando linger igual a
zero x igual a all então está batendo o
tempo inteiro então eu gosto de
trabalhar com cáfica em batchs menores
para melhorar a forma como ele trabalha
com tanto a gravação como a resposta
então batch no cáfica para o equipe o
que pareça é interessante mas batch que
a gente está falando gente eu comentei
lá no começo do treinamento batch para a
gente ainda assim é milissegundo nós
estamos trabalhando em tempo real o
batch não batch em comum vocês estão
acostumados não então é interessante
trabalhar com batch no cáfica porém
ainda estou abaixo de segundo para
garantir um tempo de resposta no
pipeline como um todo de baixa latência
outro detalhe importante compressão
dependendo da situação é interessante a
gente comprimir o dado para a questão de
volumetria a gente joga um pouco de
recurso computacional para o broker vai
ter um pouco mais de recurso de CPU
porém ainda assim é recomendado por
conta do network a troca de informação
de network então comprimido é mais
rápido e melhor aqui eu trouxe para
vocês algumas métricas para vocês
entenderem um pouquinho então por
exemplo a gente vai fazer o throughput
um link de 60 milissegundos a mil bytes
ele vai ter um throughput de 8 megas por
segundo que é considerável se eu faço um
batch de 50 eu vou ter um throughput
maior de 140 megas por segundo batch
size de 500 60 milissegundos eu vou ter
79 então eu posso ter batches menores
que eu vou ter um throughput por segundo
somente alto então o ideal é a gente
trabalhar assim compressão vamos falar
de uma compressão 10 milissegundos sem
compressão eu vou ter um throughput de
55 milissegundos se eu começar a
habilitar a compressão principalmente a
ld4 eu vou ter 293 megabytes por segundo
de throughput então eu vou só ter o meu
throughput beleza sempre tentem testar
ver se funciona legal para ver qual que
vai ser o melhor caso para vocês mas
sempre pensem em compressão e batching
no cáfeta eu sou produzindo dados beleza
por último eu vou falar aqui rapidinho
de stick partitioning antes de passar
para demo que aí eu fico só na demo
quanto maior o throughput melhor
perfeito quanto maior eu tenho mais
megas eu consigo planejar por segundo
mais eu vou conseguir mandar para o
cáfeta então assim
vamos lá tem uma kip kip 400 eu acho que
eu não coloquei ela aqui kip 480 kip 480
que ela trouxe o stick partitioning como
é que ele funciona normalmente quando o
partitioner ele vai mandar para o cáfeta
ele começa a alocar road robin mesmo sem
partição estou com chave comecei a fazer
road robin eu vou colocar aqui a chave 1
chave 2 chave 3 chave 4 independente eu
vou fazer road robin de novo aqui eu vou
ter chave mas não estou falando a mesma
chave chaves diferentes eventos
diferentes eu vou ter que fazer road
robin quando eu vou ler um tópico pelo
fardo de não trabalhar com filtro eu vou
ler o tópico eu vou procurar a partição
inteira eu vou ler todas as chaves ou eu
leio o final ou eu leio o começo a gente
já comentou earnest ou latest a gente
vai falar bastante na parte do latest
mas só precisa já entender quando eu for
ler eu sempre vou ler o começo ou tudo e
eu não vou procurar uma chave específica
porque eu não tenho como eu comentei no
início eu não tenho um índice eu não
trabalho com índice então então , isso
aqui não é performático eu vou ter que
nessa partição eu vou ter que nessa
partição nessa partição nessa partição
nessa partição e nessa partição eu leio
meu dado como um todo se eu chego de 1 a
6 aqui eu vou ter que ler assim em nível
de leitura não é interessante o stick
partition o que ele foi?
ele foi para alocar mais eventos na
mesma partição ou seja tem eventos
diferentes eles ficam diferentes 1, 2 e
3 quando eu for ler eu leio duas
partições só bem mais rápido na hora da
leitura tá?
então o stick partition ele vem em 2019
para ser mais rápido é uma configuração
que a gente faz também em nível producer
beleza?
que a gente tem que fazer e aqui é a
chave nova tá?
aqui eu não tenho eu não tenho chave por
quê?
porque aqui eu melhorar a forma como eu
vou ler se eu não tiver chave eu melhoro
o roadrunner mas de novo ainda assim
chave é a melhor forma tá?
porque eu estou colocando eventos
diferentes beleza?
stick partition também?
então vamos para a parte código vocês
querem ver código vamos mostrar código
então vamos para código peraí deixa eu
só abrir
aqui estão vendo o patch army?
perfeito perfeito vamos lá gente vou
mostrar para vocês o producer tá?
vamos pegar aqui mas antes de mostrar o
producer eu vou mostrar rapidamente o
nosso dataset lá no nosso repositório eu
criei para vocês um dataset eu vou falar
isso agora eu vou falar isso aqui na
área de connect financeiro que faz
sentido para o nosso treinamento é usar
esse use case então aqui eu tenho um use
case financeiro eu tenho o account bem
cruzão só para a gente ter dados para a
gente poder trabalhar eu vou ter
informações de account eu vou ter
informações de cartão de crédito de
transação eu vou ter investimento e eu
vou ter usuário eu vou ter informações
de usuário aqui dentro esse é um pouco é
um faker eu estou mocando dados aqui
para a gente poder trabalhar com os apps
stores para a gente poder ter massa de
dados lá na minha partinha de producer
eu vou ter eu vou mostrar primeiro o
producer depois eu mostro o setting dele
para vocês entenderem aí o produto do
meu producer pega um JSON em árvore eu
vou explicar porque é diferente então
aqui deixa eu abaixar aqui para que não
precisar eu vou ter meu producer que eu
estou usando confluent kafka então vocês
têm que baixar o confluent kafka aqui eu
tenho eu estou usando o meu settings e
eu vou explicar o settings a gente vai
abrir o settings lá dentro vocês
poderiam ver as configurações eu acabei
de comentar e aqui eu tenho um login
para a gente poder mostrar o que está
acontecendo então uma classe aqui eu
criei uma classe de abstract para
trabalhar com kafka em que eu tenho essa
função das configurações eu passo qual
configuração que eu quero usar aí vai
ler a minha função JSON que eu tenho em
settings vai instanciar o meu dado aqui
eu trabalhando o meu dado tá?
para ver se ele está se ele está
formatado se é tal objeto que eu estou
querendo se eu estou pegando o dado que
está naquela da minha classe de data gen
para aqui para dentro e eu vou criar um
for tá?
aqui eu vou ter gente tanto o lado de
consumir e produzir eu vou lutar porque
a partir do momento que a aplicação liga
não desliga mais eu sei quando começa
mas eu não sei quando termina tá?
e aqui que é importante ó eu tenho meu
producer eu estou passando nele aqui a
chave e eu vou né que está vindo aqui eu
estou lendo meu dado eu estou falando
olha procura para mim uma informação de
ID tá?
para você alocar se não tiver não coloca
vai ser sem chave e o meu valor só que
aqui ó isso aqui gente ó que a galera
não faz função de callback tá?
vamos abrir a função de callback antes
da o que ele faz?
ele simplesmente quando for acionado ele
vai formatar a mensagem que está vindo é
isso é uma coisa extremamente simples
mas é simples que não usam e aí quando a
gente vai trabalhar com um cara que é de
consultoria eu falo assim cara vamos ver
os erros que estão retornando do
producer quando você executa vamos ver o
retorno do callback por causa de uma
linha tá?
uma linha assim né?
vamos botar aqui que é esse aqui eu
estou colocando JSON e árvore diferentes
e aí 1, 2, 3, 4, 5, 6, 7 vou botar uma
linha praticamente mas são sete linhas
aqui pequenas né?
sete linhas, oito com a função de
callback lá então isso é o que a gente
sempre pede tá?
então dentro do código vocês vão ter
acesso de novo se eu não passei chave
aqui vamos supor que vocês vão pegar um
código vocês não querem testar brincar
porque é vontade tá gente?
eu vou mandar sem código ele também está
preparado aqui para mandar só o valor e
de novo não é prioritário eu sempre
mandar chave é só na própria prática tá?
executo faço o flush de mensagens tá?
e acabou aqui é o pool interval porque
eu vou fazer o que?
eu vou mandar dados baseados no pool só
que isso aqui é a minha interação entre
producer e Kafka vamos ver o nosso
settings deixei aqui bonitinho para
vocês então aqui eu estava testando
algumas coisas de autenticação para no
último dia isso aqui eu faço no último
dia olha aqui eu criei uma função at
most client id o meu broker ó x o all
zero né linger zero eu quero bater
mandar tá?
e cada vez que eu vou interagir eu vou
fazer um backslide de mil ou um
backslide até menor tá?
eu vou fazer um backslide de cem e aqui
eu coloquei max inflow requests
quantidade de conexões de requests que
eu posso mandar em uma conexão única
cinco então eu posso mandar cinco
requests ao mesmo tempo dentro de uma
única conexão qual que é o problema
disso?
se uma das requests falhar o meu meu
dado vai ser desordenado tá?
não é vindo beleza?
além disso eu tenho o o at list aqui que
eu vou meter com vocês ó x igual a um o
linger aqui vamos aumentar um pouquinho
pra não ficar feio linger igual a dez
milissegundos aqui é milissegundos tá?
detalhe importante vocês vão ver
configurações não questão do linger mas
vão ter algumas configurações que vai
ter baseado em horas ou vai ter
megabytes kilobytes bytes o cálculo fica
sempre vai priorizar a menor ou menor
medida então se você tiver alguma
configuração de hora minuto milissegundo
que ele faz a mesma coisa ele vai
considerar o milissegundo tá?
isso é questão de prova também eles
perguntam isso eles fazem isso com a de
retenção retention time beleza?
aqui eu coloquei max in flash request
igual a três e aí o meu padrão é o x que
eu comentei com vocês x igual linger por
exemplo e nem enable id pontens e
costitro pra me habilitar o hexágono
semânticos o backslider de 500 eu tô
habilitando compressão max in fly
request igual a 1 e max retries igual a
10 podia colocar aqui igual a 100 por
exemplo tudo bem até
aí?
vira um código não há alguma dúvida por
enquanto posso seguir posso mostrar ele
rodando depois eu vou entrar no diablo
tá?
aqui eu tô fazendo json beleza vamos no
json aqui pra gente terminar o json ok?
vem aqui no json o que eu tô fazendo lá
na minha função lá na minha classe de
datagen eu tô lendo ela aqui os stocks e
users tô trazendo aqui tô setando um
start date e um end date pro stocks eu
vou colocar isso como padrão depois eu
vou terminar esse código aqui eu tô
mandando 500 então ele vai ler 500
interações e gravar aqui o datagen que
vai justificar vai fazer quanto tempo
quanto que eu vou fazer pra poder
colocar ele pra ficar gerando sem parar
tá bem?
que normalmente é assim aqui é só pra
gente testar tô instanciando meu broker
e as minhas meus tópicos tá?
aqui meu tópico aqui meu tópico que eu
tô usando um tô usando um tô setando
users pra poder carregar os boxes aqui
na
verdade que na verdade as minhas eu tô
eu tô linkando tudo isso é um modo que
vocês poderiam fazer as queries
posteriormente tá?
todos os meus datasets eles estão eles
estão linkados pelo user id então o user
id eu tenho lá 20 mil user ids que vão
ser únicos que eles vão estar em todos
os datasets então pra fazer query join
que a gente vai ver daqui a pouco que
vai vir amanhã a gente vai usar o user
id pra conectar o dataset no stream tá?
beleza então aqui eu tenho client id
comentei com vocês aqui eu chamo minha
função eu tenho uma identificação igual
a false e aqui eu tô executando a função
então aqui eu chamo a class e executo a
função aqui passamos parâmetros de
tópico client e object que eu vou
trabalhar né?
se eu não fiz nada de errado eu vou
aumentar aqui pra botar 100 já prossegue
mais rapidinho então aqui eu vou mandar
executar e ele vai começar a gravar
dentro do meu gráfico lembra do offset?
partição e offset tá?
ou seja a primeira eu coloquei pra ele
retornar pra mim em qual partição que
ele tá gravando e em qual offset que ele
tá gravando tá?
então ele pegou as 500 e já a 100 e já
gravou até aí tamo
ok?
todo mundo vivo?
todo mundo entendeu?
ótimo producerável tá?
depois eu vou ler os dois pra vocês
poderem ver é producerável olha aqui
esse aqui já fica mais legal tá?
por isso que eu mostrei primeiro um
depois eu mostro o outro tá?
gente deixa eu ver se ninguém tem uma
pergunta deixa eu
conferir beleza deixa eu ter uma
pergunta pra vocês conferem conferem cá
então beleza aqui eu trago meu producer
eu trago meu client de esquema registry
porque eu quero gravar em Avro agora eu
quero usar esquema registry agora eu
quero usar a melhor prática eu vou
serializar o dado em Avro também então
eu vou trazer também dentro do meu
confronto de caso que é esquema registry
.avro pra me serializar ele eu vou criar
alguns campos de mensagem e serialização
de contexto também pra trabalhar com log
vou trazer o meu minha função de
callback cadê?
aqui ó lógico qualquer aplicação no
imposto de realizador que você vai usar
funciona de callback tá?
eu vou começar a executar o que eu
preciso aqui?
olha só que legal eu vou trazer o meu
esquema aqui eu tenho uma função pra ler
lembra eu mostrei no início lá aquele
JSON esquema que eu criei?
aqui eu trago esse JSON esquema eu
trabalho ele tá?
trago ele aqui por quê?
porque eu tenho que passar o meu esquema
aqui dentro meu arquivo de esquema que
eu tô gravando tá?
poderia ler isso aqui de um GitHub e
cara eu já vi muitas implementações bem
legais eu vi implementação o cara ele
tinha um JFrog pra sincronizar ele tinha
três repositórios um de esquema um de
produtos que a gente consome e o JFrog
fazia a integração a comunicação entre
quem que tá lendo o esquema A do tópico
A ou esquema A do tópico B porque tinha
nesse caso comentei com vocês que tinha
mais um esquema naquele tópico e o de
novo esquema reto ele libera você fazer
isso e você usar a estratégia de esquema
pra mais um tópico tá?
ele tem essa estratégia pra você poder
fazer eu basicamente não recomendo de
novo eu gosto de um pra um quando você
vai processar a gente vai ver isso cara
é um parto tá?
e de novo fica complexo o ambiente sem
necessidade eu penso um tópico como se
fosse uma tabela um pra um eu tenho um
tipo de dado pra aquele tópico ah eu vou
ter mil tópicos beleza eu prefiro tá?
o fato de gerenciar na verdade do que
parece então beleza eu vou fazer o load
né?
dos meus esquemas vou trazer a minha URL
do meu esquema registry tá?
vou serializar ele baseado naquele meu
como eu falei do meu esquema aqui meu
esquema JSON já em JSON dumps então eu
vou trazer ele aqui e vou trazer ele
aqui pra dentro aqui a mesma coisa do
outro vou trazer o objeto que eu quero
gravar vou fazer aqui a procura de ID e
aqui ó eu vou fazer assim olha a minha
chave ela tá dentro do meu avro
serializer que eu já serializei e ele já
em avro aqui dentro então olha aqui no
contexto ID tá?
dentro do meu field campo key aqui o meu
value serializei com value e a mesma
coisa e aqui eu vou fazer um lambda pra
ele poder se der algum erro aqui uma
função lambda dentro do Python pra poder
pegar o meu a minha função de callback
caso dê algum problema tá?
aqui a minha função de callback faço o
load as mensagens é a mesma coisa se der
algum problema aqui eu tenho um buffer
erro eu tenho uma exception também tá?
se der algum erro na minha aplicação eu
inivo a aplicação não inivo a
comunicação de metadábulas entre Kafka e
Produscer vamos ver se tem que ir
rodando então aqui ó eu venho aqui o que
eu tô fazendo usuários tá?
usuário tá aqui eu vou passar ele pra
sem não, sem usuários é o meu broker tá
certinho o meu schema registry deixa eu
abrir aqui assim o meu broker o meu path
do meu schema aqui ó meu schema tá aqui
ó eu tô passando numa abstração se vocês
quiserem brincar e testar uma abstração
vocês podem mudar a aplicação como vocês
quiserem eu devo mexer mais nela nos
próximos treinamentos tá?
então eu tenho aqui tanto o key como o
value aqui eu vou trazer as
configurações de acesso ao broker broker
schema registry né?
não tem autenticação por isso que tá
aberto pra teste na minha função eu vou
falar quem que é quem olha o meu schema
aqui meu topic é esse aqui e eu posso
criar também, tá gente?
na verdade esse aqui é o que eu criei
pra esse treinamento mas eu tinha um
repositório anterior que você pode
trocar esse num .env você pode botar
esse num .env dentro do do Python aqui e
você chamar ele dentro lá não tem
problema nenhum aqui eu fiz mais pra
gente poder ter mais claro e ver isso
aqui na tela não vai ter que ficar
abrindo arquivo .env mas pode trocar com
variável de ambiente executo né?
vamos ver aqui mandei stem e eu vou
fazer uma coisa bem legal
eu vou abrir o terminal eu vou mostrar
aqui tanto a inserção e a gente
consumindo via console tá?
não vou mostrar ainda o consumo porque
eu quero mostrar o consumo na prática no
quarto dia então aqui é isso aí tá
vendo?
aqui eu tô fazendo a mensagem aqui eu
peguei eu não só peguei o que eu fiz
diferente pra vocês poderem ver eu
peguei também a mensagem que eu tô
mostrando na tela tá?
que eu gravei mas será que eu gravei?
vamos fazer uma brincadeira aqui pra
gente fazer o nosso intervalo tá?
vocês estão fera?
dá pra gente fazer até uma pausa de 15
minutos deixa eu pegar aqui tá aqui
não eu falei que é use exact vamos pegar
esse cara aqui eu vou compartilhar tá
gente?
não esqueci não que eu vou fazer isso em
duas
partes verdade?
eu vou fazer assim deixa eu distanciar
aqui esse que tá pegando
vai ser massa hein?
olha só vamos ver isso aqui meus amigos
porção ó do lado do terminal que vocês
estão vendo aqui eu tô com vou ver se
deixa eu ver se não se passa
do lado do terminal aqui eu tô com
KafkaCat que é esse comando aqui tá?
é aquele comando que eu mostrei que ele
tá consumindo os dados que estão naquele
topo que eu acabei de criar que eu
acabei de executar então aqui ele parou
de consumir porque chegou no final dele
se eu fizer isso vou lá tem que inserir
aqui embaixo aí começou a consumir tá
vendo?
ele tá ali importante eu tô na minha
máquina digital ocean digital ocean eu
tô lendo aqui de novo então né eu tô eu
tô indo pra internet e na internet eu tô
buscando esses dados é muito rápido se a
gente vai lá pensar tá?
então vamos botar mais aqui vamos passar
por uns 1500
e aqui eu tô usando x igual a 1 então já
foi né?
rapidinho então eu tô usando também
linger habilitar x igual a 1 então vocês
vão ver o poder do Kafka aqui eu tô
usando uma máquina bem humilde aqui tá?
tô com 1 giga de memória do Kafka e meio
CPU então tem 3 nós 3 gigas total tá?
então a questão de processamento de como
é que vai armazenar aqui é um upload
pequeno a gente tá colocando 1500
mensagens né?
então vamos vamos exagerar aqui um
pouquinho eu vou testando tá?
eu vou mostrar pra vocês um benchmark no
último dia que eu vou colocar vou
ingressar 1 bilhão de mensagens tá?
pra começar a quebrar o ambiente eu vou
mostrar pra vocês como é que vocês
testam ambientes já foi já também assim
vamos fazer a pausa vamos voltar vamos
fazer 15 minutos hoje a gente volta 9 e
eu falo só de connect que aí vai ficar
mais legal aí eu falo de connect que aí
a gente vai falar um encapsulamento do
connect pra producer e a gente segue aí
vai ser 40 no máximo uma hora não vai
passar disso não e aí eu sei que vocês
estão com mais dúvida de connect então
eu vou detalhar bastante tá?
então vou fazer a pausa aqui então vou