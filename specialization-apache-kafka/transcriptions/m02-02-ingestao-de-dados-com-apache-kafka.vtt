Perfeito.
Gente, vamos lá.
Então, a gente falou de producer, né?
A gente entendeu como é que eu vou
produzir dados, como é que eu vou
trabalhar com dados.
Agora, vamos trabalhar com Kafka
Connect.
Eu comentei inicialmente que ele é uma
API de integração.
E é normal que tiveram dúvidas.
Agora, a gente vai suprir essas dúvidas,
né?
Então, o que é o Kafka Connect?
O Kafka Connect é simplesmente a ideia
de um framework open source de
integração que vai ler dados de uma
fonte e inserir dados no Kafka, o que eu
chamo de source, e eu vou fazer o sync.
Eu vou pegar os dados do Kafka e inserir
em outro lugar.
Em formato JSON, Parquet, seja o que
for, dependendo do conector que eu usar.
Então, eu uso o conceito de conectores
ou plugins, tá?
Eu vi muito isso lá fora recentemente,
mas geralmente fala conector.
Beleza?
Então, o source.
Eu vou ler os dados de um banco de
dados, às vezes que ele serve, Postgres,
MySQL, MongoDB, seja qual for.
Vou trazer esses dados para dentro do
Kafka usando uma linguagem declarativa
que eu vou explicar daqui a pouco.
Então, o Kafka Connect, gente, olha que
maravilha.
E particularmente, tá?
Foi o primeiro projeto de Kafka que eu
trabalhei, foi exclusivamente com Kafka
Connect.
Porque, de novo, né?
Eu vim da área de dados.
Então, eu não tinha expertise em
programação.
Então, deve ter aí os últimos três anos
aí que eu tenho trabalhado bastante com
produtos de consumer.
Quatro, mas tem cinco anos que eu
trabalho com Kafka.
Então, foi praticamente um ano inteiro
eu trabalhando somente com o Connect,
tá?
Então, banco de dados, source, né?
Encapsulado, o source é o quê?
É um producer que vocês acabaram de ver.
Só que ele é encapsulado, tá?
Eu vou mostrar por que que é esse
encapsulamento.
Então, ele é encapsulado, onde eu tenho
um cluster de Connect.
Aqui eu tenho um worker1, um worker2,
que é o nome do nó que eu vou dar.
Lembra que eu falei do broker?
Eu tenho um broker dentro do nó de
cluster de Kafka e aqui eu tenho um
worker dentro do nó de cluster de
Connect.
Então, aqui eu tenho dois workers, tá?
Em que eles estão executando aqui, os
meus conectores, acessando o banco de
dados ou inserindo dados em data lakes,
por exemplo, tá?
De novo, source, eu conecto, né, no
banco e trago para o Kafka.
Sync, eu remuto, ou tipo, mudo aquele
dado do Kafka para uma outra fonte,
beleza?
E por que que o Connect é uma linguagem
declarativa?
Eu mostrei, lembra que eu mostrei um
pedaço do...
Aqui está o pedaço daquele meu producer
que eu mostrei para vocês.
Mas é um pedaço do producer.
Pensa se eu tiver tudo embedado, num
arquivo de configuração, que não é só o
producer.
É a minha também integração com o meu
source.
Então, aqui eu vou ter também as
bibliotecas, todo o processo necessário,
os drivers, para eu acessar um banco de
dados, toda a interação com o banco de
dados e trazer aquele dado para dentro
do Kafka.
Então, eu falo que ele é um bundle, né?
Qual que é o legal?
De novo, é um arquivo de configuração.
Não tem uma magia, não tem uma
configuração, não tem uma programação.
Eu não tenho essa programação.
Eu simplesmente passo a minha classe, o
meu plugin, de novo, é um arquivo de
chave -valor.
Qual que vai ser o meu serializador?
Aqui eu estou usando, por exemplo, o
Avro, né?
Conectando o Schema Registry ao meu
banco de dados, a porta, o nome da minha
base, o meu usuário e senha, as tabelas
que eu vou trabalhar.
Aqui, por exemplo, é um CDC, tá?
Aqui é um E -Biz, um CDC, né?
Aqui é um E -Biz, um CDC.
E aqui eu tenho as configurações daqui
para baixo.
Específicas, né?
Esse pedaço aqui do E -Biz.
Importante eu precisar, sempre, sempre,
olhem a documentação do conector.
Por quê?
Nem todas as configurações que vocês
podem fazer com o producer vão estar
disponíveis para o conector, tá?
Elas podem estar mascaradas, até mesmo
desabilitadas, porque o conector, ele é
mais inflexível.
Ele já é um...
Ele é um bundle.
Ele não dá para fazer qualquer coisa
através dele.
Não é uma interface que eu vou trabalhar
com o producer em si.
Ele está encapsulado.
Então, quem desenvolveu pode ter
escolhido somente certas configurações
para serem modificadas.
E o resto, o próprio conector toma
aquilo como sendo configurações
principais.
Por exemplo, não são todos os conectores
que eles trabalham com X igual a O.
Exato, eu vou a semantics.
Tem que virar com a documentação.
Porque grande parte dos conectores
trabalham...
Trabalham com X igual a O, que é o
default do cargo, tá?
Ou seja, pode ser duplicado.
Lógico que DB -CDC, JDBC, SYNC do EC3,
por exemplo, trabalham com a exacto
semantics.
Vão ver na documentação.
Sempre abra uma documentação e procure
impor nível message guarantee, delivery
guarantee.
Qual que é o nível de garantia?
Exactly, at once, at most.
Ele vai te falar na documentação, tá?
Porque, de novo, é algo que quem
desenvolveu que vai colocar.
E você não consegue forçar aqui.
Esse é um exemplo clássico.
Você não consegue.
Beleza?
Então, é uma linguagem declarativa por
conta disso.
A gente tem o nosso.
A gente vai ver esse cara rodando na
prática aqui.
Tipos de deployments do meu connect, tá?
Ou seja, o meu servidor.
Eu posso trabalhar em single worker.
Onde os meus arquivos de configuração
vão estar gravados dentro do meu worker.
Ou seja, eu tenho um arquivo de offset,
config status.
Porque ele tem que se coordenar.
Pensa no que eu comentei, né?
Lembra que o conector, ele é uma
aplicação embedada?
Então, ele vai falar assim, olha.
Qual status o meu conector está?
Está running?
Se parou?
Se executou?
Eu posso restartar ele?
Qual a configuração que esse conector
tem nessa execução?
E qual a configuração de offset que ele
tem?
Que ele vai coordenar várias tarefas,
testes diferentes e por aí vai.
Então, ele realmente é um bando.
Então, eu posso fazer stand alone para
desenvolvimento.
Aqui é para desenvolvimento.
Eu faço um single worker.
E aí, eu uso o tipo stand alone.
Onde ele vai gravar localmente em
arquivo, em disco, no servidor que está
usando.
Mas o comumente usado é o tipo
distribuído.
Que ele cria topics.
Dentro do meu broker.
Que eu vou falar assim, olha gente.
Esse connect aqui, ele vai carregar os
dados para esse broker.
Então, eu falo para qual broker que ele
vai dar.
Porque ele é dependente, tá?
Um connect, ele não trabalha sozinho.
Precisa de um broker para ele poder
conectar.
Então, eu quero falar assim, olha.
Esses são os brokers que eu vou
trabalhar.
Cria, porque ele está mó distribuído.
Cria para mim os meus topics de sistema
para o meu connect.
Ele cria topics dentro dele, tá?
Qualquer vantagem disso.
Os topics são distribuídos dentro de
Kafka.
Tem resiliência e por aí vai.
Então, a gente usa o Kafka como uma
forma de gravar os metadados aqui.
Esse é o mais comum, tá?
Até mesmo porque eu posso fazer isso
aqui, olha.
Eu posso ter as minhas...
Eu vou explicar a task, tá?
Mas eu posso ter minhas tarefas
distribuídas entre os workers.
Então, aqui eu tenho dois.
A tarefa do conector A.
Ela está um aqui, dois aqui.
E aqui está um aqui, dois aqui.
Ou seja.
Esse conector, ele está instanciado nos
dois workers.
O que é bem mais rápido, tá?
Para poder fazer.
Nesse caso aqui, por exemplo, eu vou ter
dois caras gravando ao mesmo tempo.
Cada worker vai estar gravando o que a
task está lendo.
Então, a task está lendo da tabela e
está gravando no banco, no caso do
source aqui.
Beleza?
Então, eu posso distribuir as tarefas
para a execução entre os workers.
Não é simplesmente um conector inteiro
vai ficar dentro.
Não.
Eu posso distribuir em uma tarefa.
Mas eu tenho que ir trabalhando com o
distributed mode.
Porque se eu estiver trabalhando no
single ou no stand alone.
Mesmo se eu tiver mais um worker aqui.
Ah, eu quero trabalhar no stand alone.
Mas eu posso ter mais um worker?
Pode.
Cada worker vai hospedar uma das tasks
daquele conector.
Ele não vai distribuir aqui.
Porque ele não vai ter como se coordenar
usando aqui o distributed mode
distribuído.
Então, é muito importante.
Eu vou mostrar onde é que tem essa
configuração do YAML e do connect.
Beleza?
Anatomia de um conector.
Então, a gente vai ter aqui primeiro o
tipo dele.
Ele vai ser um Elasticsearch, o source.
Ele vai ser um FileStream.
Ele vai ser nota DBC.
Ele vai ser um MQT Series.
Ele vai ser um Active.
Qual que é.
Ele vai pegar qual que é a classe que
ele vai trabalhar.
Se é um nível de classe.
Aqui ele vai falar assim.
Olha, se eu tiver transformação no meio
do caminho.
Eu faço a transformação primeiro.
E depois eu converto.
E depois eu ensino lá.
Então, dentro da task ele vai ter esses
processos aqui.
Transformação é caso houver.
O que a gente chama de SMT.
Simple Message Transformation.
Então, eu posso sim.
Em nível dos meus eventos que estão
acontecendo.
Eu posso fazer transformações simples.
Por exemplo.
Posso fazer cast.
Eu posso dropar uma coluna.
Eu posso extrair um campo.
Eu posso extrair dados em um tópico.
Eu posso mascarar um campo.
Eu posso converter.
Então, eu posso fazer algumas
transformações.
Fazer um flapping.
Eu pego aquele JSON.
E transformo ele em um modo mais
tabular.
Dentro dele.
Então, eu faço.
Eu quebro ele em colunas.
Em várias colunas.
Isso aqui eu uso bastante.
Por exemplo.
Para SMT.
Para o CDC.
Então, primeiro ele faz a transformação.
Depois ele converte.
Esse é o processo normal.
Se tiver transformação.
Ele vai passar aqui.
E vai para a conversão de uma vez.
O converter.
O que é?
É JSON.
Qual é o caracterizador que ele vai
estar utilizando.
Aqui.
Batch Array.
String.
Avro.
JSON.
Protobuf.
Isso aqui é a forma que ele vai
executar.
Bom.
Vamos ver o Connect.
Eu vou mostrar o Connect primeiro.
Depois eu vou mostrar os conectores.
Vamos começar por parte.
Até alguma dúvida?
Dúvidas?
Não?
Marcos.
Perfeito.
Deixa eu.
Pode perguntar.
Estou trocando de tela aqui.
Pode perguntar.
Pode.
Ô Matheus.
Boa noite.
No caso do.
Do conector.
A gente sabe que.
A gente.
A gente tem vários.
Vários conectores aí.
Que atendem.
Diversos providers.
Né?
Então.
Quando.
Quero.
Quero.
Trazer.
Uma mensagem.
De um.
De um CDC.
De.
SQL Server.
Eu tenho.
Já.
Já.
Pré -definido.
Né?
Tipo assim.
Já.
Já compilado.
Ali.
Né?
É.
Pelo.
Pelo.
Vou falar do.
Que eu.
Acho que.
É o.
Mais comum.
Aí.
Que a gente.
A gente.
Trabalha.
É.
Tem.
Algum.
Assim.
Como.
Boa.
Prática.
Né?
O que.
Que.
Você.
Aconselha.
A gente.
Tipo.
Assim.
De.
Sempre.
Sempre.
Manter.
Atento.
A questão.
De.
Diversionamento.
Do.
Do.
Conector.
É.
Eu.
Posso.
Por.
Exemplo.
É.
Pela.
Pela.
Sua.
Experiência.
E.
Que.
Você.
Já.
Viu.
E.
Que.
Você.
Pode.
Orientar.
A.
Gente.
É.
Sempre.
Como.
Boa.
Prática.
E.
De.
De.
Sempre.
Estar.
Olhando.
Até.
Para.
Para.
Versões.
De.
Conector.
Sabe.
É.
Não.
Sei.
Há.
Uma.
Uma.
Uma.
Ligação.
Por.
Exemplo.
Sai.
Uma.
Versão.
Do.
Do.
S.
Que.
Serve.
Que.
O.
Time.
De.
DBA.
É.
Só.
De.
Uma.
Versão.
Nova.
Lado.
Da.
Da.
Instância.
E.
O.
Nosso.
Conector.
Aqui.
Ele.
Está.
Muito.
Defasado.
Em.
Relação.
Essa.
Versão.
Nova.
Lá.
Do.
Lado.
Do.
DBA.
Sabe.
Entendi.
Então.
É.
Mais.
Mais.
Assim.
Nessa.
Questão.
De.
Boas.
Práticas.
Mesmo.
Que.
Que.
Você.
Recomenda.
Para.
Gente.
Perfeito.
Sempre.
Vocês.
Vão.
Procurar.
Sempre.
Testar.
Novas.
Versões.
Por que.
Que.
Eu.
Falo.
Isso.
Para.
Os.
Bancos.
Geralmente.
Eles.
Saem.
Nos.
Conectores.
Mais.
Recentes.
Você.
Comentou.
Talvez.
Uma.
Melhoria.
No.
Meta.
Dado.
Do.
Cdc.
Quando.
Você.
Habilita.
A.
Estabelecer.
Esse.
É.
Traz.
Uma.
Melhoria.
No.
Conector.
Em.
Si.
Se.
Estava.
No.
Antigo.
Eu.
Estava.
No.
Método.
Anterior.
Não.
Está.
Conseguindo.
Pegar.
Na.
Melhoria.
É.
De.
No.
Número.
Então.
É.
Faz sentido.
Mas.
Você.
Pensar.
Do.
Tipo.
Sempre.
Tentarem.
Não.
Perder.
Muito.
É.
Essas.
Esse.
Dicionamento.
De.
Conectores.
Contra.
A.
Questão.
De.
Cdc.
De.
De.
Cd.
É.
É.
Um.
Pouco.
Mais.
Complicado.
No.
Conector.
Porque.
Ele.
Não.
Depende.
Somente.
Dele.
Pode.
Ter.
A.
Questão.
Também.
De.
Outras.
Dependências.
Eu.
Vou.
Mostrar.
Que.
Na.
Parte.
De.
Conect.
Tem.
Versão.
Por.
Exemplo.
A.
Questão.
Do.
Conector.
Mais.
A.
Versão.
Do.
Avro.
Por.
Exemplo.
Tem.
Que.
Pegar.
Os.
Dois.
Jars.
Ou.
Então.
O.
Jar.
Do.
Avro.
Isso.
Não.
Gente.
Isso.
Aqui.
Um.
A.
Briga.
Que.
A gente.
Vai.
Ter.
Eu.
Sempre.
Falo.
Cara.
Big.
Data.
Complicado.
Vou.
Falar.
Complicado.
De.
Data.
Eu.
Já.
Quem.
Trabalha.
Com.
Spark.
Sabe.
Disso.
Quem.
Trabalha.
Com.
Connect.
Isso.
Quem.
Trabalha.
Com.
Link.
Eu.
Estava.
No.
Treinamento.
Aqui.
Uma.
Aplicação.
Sofre.
Com.
Já.
Então.
Já.
É.
Uma.
Coisa.
Um.
Pouco.
Mais.
Complicado.
Porque.
Tem.
Versões.
Dele.
Que.
Não.
Vai.
Conversar.
Um.
Com.
Outro.
Então.
Sim.
Você.
Pode.
Ter.
Alguns.
Problemas.
O.
Ideal.
É.
Você.
Ter.
Um.
Ambiente.
De.
Test.
Tá.
No.
Ambiente.
De.
Stage.
Onde.
Você.
Consegue.
Testar.
Os.
Seus.
Os.
Conectores.
É.
Nem.
Seja.
Em.
Dock.
Pode.
Ser.
Até.
Local.
Você.
Tem.
Algum.
Processo.
Em.
Dock.
Para.
Poder.
Testar.
Esses.
Conectores.
Tá.
E.
Sim.
Não.
Tem.
O.
Atualizado.
Possível.
A.
Recomendação.
Que.
De.
Novo.
Ele.
Sofre.
Em.
But.
Fix.
É.
Melhorias.
Tem.
Muito.
O.
O C.
D.
O.
C.
Tive.
Muitos.
Erros.
Open a.
D.
Essa.
Ir.
É.
É.
Bem.
É.
É.
Assim.
Dá.
Para.
A.
Gente.
Poder.
Sempre.
Sem.
Re.
não, mas é ideal você sempre colocar
isso lá, cara, isso não é uma coisa que
eu posso deixar e acabou e o Kafka tem
muito disso, eu vejo muitas empresas
pensarem assim o Kafka funciona muito
bem, eu vou deixar ele ali até e eu
peguei Kafka 0 .11 então assim, a
segunda versão do Kafka praticamente é
mais utilizada, quando ele saiu ele saiu
na 0 .7 ele começou a ser traçado em 0
.11 então peguei, cara, e isso quando já
tinha 2 .5 2 .4, então assim, estava
anos e anos na frente então assim, então
é muito cuidado
contra referente a versionamento o
Connect é a mesma coisa então é muito
cuidado mas a gente pergunta então vamos
lá, para a gente saber, e é importante
porque vai de encontro com o que eu
quero mostrar agora para a gente poder
deixa eu dar um play aqui deixa eu só
adicionar aqui o meu load balancer no
meu compo order não sei porque o load
balancer do Connect não está sendo legal
esse aqui eu sei que está então então eu
tenho alguns comandos aqui para a gente
saber, lembra que eu falei dos plugins?
o Connect é baseado em plugins então eu
vou dar aqui
um um Connect plugins e vai trazer para
mim quais plugins que eu tenho nesse
Connect qual o chip e a versão e aqui
vocês podem confrontar junto com a
versão que vocês estão, a última que
está no mercado com a que vocês estão
utilizando, esse aqui ali é do servidor
ó gente, ó já falei com o time de DevOps
olha, não precisa sentar, já precisa
mexer nas instalações desse conector que
está muito antigo, por exemplo então tem
todas essas informações, tá?
eu vou passar um pouquinho esse aqui é o
comando para
mostrar a versão atual do Connect do meu
servidor eu estou na 3 .7 .1, como eu
comentei e aqui é o meu cluster ID que
ele gera se modificou aqui, a gente pode
saber também que teve algum problema
aqui os plugins que eu já mostrei deixa
eu mostrar um outro aqui que é super
legal aqui eu mostro os conectores
rodando, quase que estão ativos só que
esse aqui, essa visão não está legal vou
dar um de equil aqui e aqui eu tenho
três conectores
ativos aqui, tá?
eles estão aqui no meu servidor, meu
servidor ele é single node mas ele é
distribuído, beleza?
e aí gente a gente entra, eu queria
mostrar para vocês rapidamente aqui na
parte de jars deixa eu mostrar para
vocês aqui isso é importante vocês
poderiam saber não?
aqui eu vou mostrar o docking mas em
defecto, tá gente?
eu vou rodar isso aqui a pasta plugins é
onde tem que
estar todo o seu jars quando vocês forem
ah, eu quero colocar um conector novo
não sei quem, tipo, é aqui não?
conhece, tá?
eu gosto de usar dois sites para poder
buscar conector deixa eu colocar aqui na
tela para vocês poderem ver e também
está a documentação de vocês eu gosto
muito do Confluent Hub eu gosto bastante
onde eu venho aqui
eu tenho conectores tanto gerenciados
como open source, tá?
então, por exemplo, o .dbc ele é open
source tá?
Averbal Self Hostage ele é Confluent
Community mas ele é open source eu posso
usar ele aqui dentro do meu cluster sem
problema nenhum baixar lá o jar baixo
ele, tá?
eu vou mostrar aqui o jar dele que está
pronto aqui dentro da pasta lib vai ter
o jar dele então se eu for aqui na .dbc
tá vendo como é complicado?
você tem que essa questão de CICD só
voltando um pouquinho nisso você tem que
ter o conjunto certo de jars por exemplo
eu estava testando a última versão 7 .7
do do do AVO tá pequenininho mas está
aqui eu estava trabalhando com a 7 .7 e
eu vi várias inconsistências com as
versões que eu estava trabalhando
anteriores não estava nem subindo com o
broker o CapConnect eu tive que parar
rebuildar uma imagem nova criar uma
imagem nova e trazer os corretos então
aqui eu gosto muito de usar testando,
validando se está ok sobe o ambiente
local brinca e aí vocês vão pegando, tá?
isso aqui porque é bem é bem complicado
mesmo não tem uma receita para esse aqui
então além dos além desses caras aqui
que são os meus plugins tá?
eu também tenho a parte dos meus das
minhas leads, né?
então tem aqui o meu o meu CapCon o meu
CapCon é a Avro Converter muita gente
pula isso, tá?
tem que tomar muito cuidado ah não,
então eu só vou instalar aqui e acabou
não tem também as leads então tem aqui a
lead de Avro JSON Schema Provider JSON é
Kafka Scheme REST Client por quê?
porque na verdade de novo lembra que o
meu conector ele é uma aplicação que ele
vai comunicar com a outra né?
ele vai ele vai ele está embedado então
tem que ter também os jars necessários
para fazer toda a minha integração então
é chatinho mas eu tenho tudo pronto para
vocês aqui e também eu vou entregar para
vocês essa aplicação que eu criei há uns
meses atrás e é para baixar os jars do
Stream Reactor tá?
o Stream Reactor é um projeto open
source que é um projeto tá?
para lentes eu tive eu falo a gente não
é que nem vendês nem nada eu tive muito
próximo a eles nos últimos meses botar
eu trabalhei um ano direto com eles para
entender essa parte comunidade open
source conector Kafka então eu fiquei
muito próximo nesse sentido e eu vi
coisas bem legais sabe?
então eu gosto muito de trabalhar com
Stream Reactor por quê?
são open source e tem umas coisas bem
legais por exemplo eles tem tanto o
source o sync do blob storage eles tem
tanto o source o sync do S3 e isso open
source e eu vou falar que eles tem umas
vantagens bem interessantes o conector é
fácil de usar tem uns SMTs próprios
também que ajudam bastante a gente tem a
parte de parcionamento em Data Lake eu
vou mostrar isso eu vou mostrar esses
caras rodando no quarto dia então eu
também gosto de usar esses caras aqui
quando eu não acho que eu quero um
component hub então os dois links estão
lá no nosso GitHub vocês vão ter acesso
a eles para a gente poder ver sabe?
então vamos seguir um pouquinho que
daqui a pouco eu quero mostrar para
vocês deixa eu mostrar primeiro aqui o
meu cluster
cluster cluster cluster aqui se eu der
um paygate
pods eu tenho o meu Kafka Connect aí
bonitão eu vou dar um klog que é o
Compute Shell só um ilha só se tinha o
logs a menos é não tenho vou dar um
tempo no arquivo de log mas não tá isso
entrava cobertura se eu for trabalhar
para ir para investigar log é muito mais
rápido também porque eu tenho comandos
diretos então que eu tenho umas
informações por exemplo tá vendo olha eu
peguei status os conectores aqui é tudo
isso aqui são comandos que eu odeio
externo e ele gravando logo então você
tem algumas informações bem
interessantes aqui tá aqui tá também
informação por exemplo contém inserção
último offset que foi executado aquele
conector tem umas coisas bem legais a
gente vai ver isso daqui a pouco na
prática então o conector também não é um
cluster é o connect desculpa o connect é
um cluster o conector é uma aplicação
que executa dentro do cluster beleza
pegaram aí eu já vi muito pessoal
falando assim ah meu connect não tá
rodando não eu sou o conector que não tá
rodando dentro do connect o connect é um
servidor que ele vai hospedar os
conectores então ele vai ter a lógica
para hospedar e executar deixa eu
continuar essa explicação um então
beleza então a gente tem o mesmo
esquema de integração é importante gente
de novo e aí Lilian uma coisa que você
falou o negócio da questão do esquema
registry como é que eu gosto de
reintegrar isso eu uso bastante também
na parte de conector então o quaker
também eu tenho integração nativa para
trabalhar bom o esquema que eu leio do
banco de novo aqui ele vai ler a
mensagem isso é importante isso é
importante para a gente ele vai ler o
banco não vai pegar o esquema do banco
que está lá não ele vai pegar a mensagem
vai interpretar e vai gerar um esquema
dela aqui dentro então eu não faço query
de sys sys tables ou sys esquema que eu
não tenho tempo para ler mas eu não faço
nenhuma query específica para ler o
esquema correto ele vai interpretar e
pode acontecer de ter problema de
esquema dele falar isso aqui é string
isso aqui é numeric então sempre tomar
cuidado com isso o quaker que vocês não
conseguirem interpretar roda um smt
fazer um cast eu costumo fazer mais
simples eu trago tudo para string e not
para não ter nenhum problema também que
eu não quero também criar um monstro na
parte de smt porque é simple simple
message transformation não é message
transformation simple é simples então eu
não gosto de jogar outro put de
processamento para o smt sozinho então
eu já trago o dado mais frio possível e
aí no processamento eu desligo o cabelo
e ali eu faço o que eu quiser a gente
vai ver isso amanhã então beleza então
vamos ver como é que funciona tá entra o
dado nativo o dado que veio do banco
nativo data o dado que veio de sistemas
que a gente chama de upstream então
sistemas de source são streams eles
entram nesse processo de conector classe
que vai ser executada eu rolo smt em
nível linha se eu tiver um smt
configurado e aqui eu serializo aquele
dado no caso a gente vai mexer aqui com
a dentro do cáfico no final das contas
vai ser byte a gente comentou binário e
aqui eu vou ler os dados eu vou fazer o
downstream por exemplo aqui é um caso
que eu posso reidratar o meu data lake
esse é um caso bem interessante pego os
dados do banco trago para o cáfico e do
cáfico eu já jogo dentro do data lake eu
faço isso continuamente a gente vai ver
isso na prática também que no final do
quarto dia isso é justamente isso eu vou
estar rodando o tópico de entrada eu vou
transformar aquele dado depois eu vou
disputar esse dado no data lake para a
gente poder ver ele lá dentro no arquivo
só que eu já posso entregar ele
processado não preciso jogar ele cru e
processar eu posso fazer isso aqui nesse
momento beleza conectores só os mais
utilizados eu vou citar aqui três caras
aqui para a gente então o primeiro é o
jdbc jdbc é o javadriver javadriver é
aqui praticamente ele conecta em
qualquer banco de dados relacional
beleza então mais é o que ele serve é
post, usuário qualquer coletor que
aceita javadriver ele vai aceitar vai
executar esse cara aqui então ele
trabalha de modo incremental eu tenho
incremental por coluna então eu passo a
coluna incremental é importante isso
gente escutem escutem a experiência que
passou por isso dado incremental o
incremental é um colo que ele procura
ele procura um
int sequencial se a tabela que vocês
tiverem tiverem
buracos ou seja um dois três sete oito
nove onze ele praticamente ele para ele
executa errado ele perde a coordenação
completa ele realmente perde ele fica
muito doido eu já vi isso acontecer ele
se perde por causa desses buracos ele se
perde então eu tenho que testar mais mas
eu tive muito problema com um cliente
com isso em que a gente teve que criar
artificialmente uma coluna sequencial
criar certa view então a gente fez uma
view que ele tinha uma query row number
que aí a gente conseguia pegar
sequencial e ir trazendo então ele já
tinha e ia carregando a gente conseguiu
fazer que a gente cdc nem o tradeiro vai
conseguir cdc então não é sempre mas ele
deixou o importante está incremental é
sua frente então incremento ou seja foi
certo não tem certo certo não tem se eu
tenho a gente tem certo só que eu tenho
opção de incrementar esse tempo e mais
incremento ou seja eu tenho o time
daquele dado e vai pegar o que ele vai
pegar o incremental e vai ver a
diferença do time aí eu consigo pegar
evidente eu consigo pegar evidente então
essas configurações aqui são os modos é
que eu tenho no meu jdbc drive jdbc tá
só se conecta não se esqueçam disso as
configurações de um não sei se você dá
os outros os outros a gente vai ver isso
aqui agora eu posso fazer quais
customizadas também não recomendo fazer
quais maravilhoso tomem cuidado com isso
eu posso fazer book que que é o book
tá dentro do modo tá na verdade eu posso
trazer table viu ou é a forma que ele
vai interagir com você vai ler tabela
toda vai ler a viu passar aqui uma viu
aí vai fazer uma coisa e aqui eu tenho o
book é o que insete tudo né tudo aqui é
tudo o tempo todo tudo o tempo todo
então eu não tenho incremental eu vou
ler tudo o tempo inteiro se a tabela é
pequena vai acontecer um caso assim é
mais fácil fazer se a tabela tinha 13
registros eu fazia um book dela e eu
simplesmente é criava como logo compacto
tá vendo logo compacto sensibilizado
logo compacto porque como eu sempre ia
ler o último eu tinha lá minha chave 13
né quando eu escrevi de novo eu tinha
mais tinha 23 registros só que como
aquele último ele deletava de um tempo
lá porque era a mesma chave você pode
também com o smt delegar a chave criar
porque automaticamente não traz chave tá
bom se você não passar o smt pra você
falar quem que é a chave no seu conector
usando smt que é o value to key ou o
create key que eu vou mostrar aqui o
create key você não consegue é ele não
vai criar chave então eu crio chave pra
tudo tá é a minha minha regra jbc
normalmente utilizado mais para append
quando você tem a tabela incremental
bonitinho tá e isso é uma briga debate
né que a gente não vai entrar agora
tabela via o query né e ele trabalha
muito bem com schema register beleza
esse cara aqui é utilizado sem ativos
ele não trabalha com at most ou at least
tá exato sem ativos mongo tá esses esse
específico é o conector só se dá própria
mongo para o cárter tá criado pelo time
do mongo db então ele trabalha com a
ideia de change streams do dos
documentos então ele pega
automaticamente ele lê os dados ele pega
o diferencial também você pode fazer o
time tem
documento que vai pegar todas as
mudanças acontecendo aqui documento as
novas e a moda alteração tá nível de
collection outra vez você pode fazer
configurações para publicar somente o
documento publicar partes específicas tá
ou copia que existe tem umas
configurações bem legais geralmente eu
tô com mongo eu gosto de usar esse cara
aqui apesar de que eu cdc eu devia cdc
de mongo eu também já testei esse cara
que tá bem legal de usar agora
antigamente eu tava quando eu peguei
peguei em 2020 então eu não tava tinha
acabado de ser lançado não tava 100 %
agora tá mais confiável tá adetado se
não me engano é os vamos ver esses o que
que é os pra gente ver se é ele mesmo
mongo aí eu vou em documentation acho
que é aqui que vai tá os ou exactly
vamos ver se ele vai tá aqui queria
mostrar isso pra vocês de um site errado
que o site aqui é do atlas eu não quero
o atlas eu quero o aí tá vendo eu tenho
aqui ó aqui eu não sei se é aqui que
fala vamos ver se é aqui que ele fala
vai em fundamentos acho que o cdc vai
ficar
mais fácil de mostrar que aqui a
documentação tem que dar uma olhada mas
sempre olha a documentação de novo né
vamos sempre precisar da documentação
pra ter certeza do site do mongo mas
sempre
procurem se ele exactly atlist sempre
pesquisem se não tiver ele vai conseguir
vai ser atlist tá porque não tiver
explicit então tá vamos eu vou confirmar
aqui tirar aqui porque eu quero mostrar
pra vocês se você quer e aqui a gente
entra no cdc antes de fazer cdc eu vou
trazer as opções do cdc pra vocês
entenderem pra quem não entende o que é
cdc tá gente então o cdc é change data
capture tá é uma tecnologia específica
ou um processo específico do banco de
dados então por exemplo eu tenho log
base em que insert update delete eles
estão dentro do transaction log e o o
cdc ele é utiliza no action log pra
acessar essas informações essas
operações tá eu tenho também o de query
em que eu crio uma query pra pegar o
diferencial baseado no timestamp esse
cara aqui não é tão utilizado na minha
opinião porque você tem que modificar
ele traz impacto no sistema de origem tá
porque você tem que ler a tabela de
origem o tempo inteiro e tem um tipo de
trigger tá que é o que aconteceu a
mudança ele triga é pra esse carro
normalmente a gente vai trabalhar mysql
o postfix trabalha com replication o sql
server trabalha com a tecnologia do cdc
da própria sql a gente vai trabalhar com
esse processo aqui tá ler o transaction
log no próprio no caso cdc do sql server
vou mostrar aqui ele trabalha com o cdc
do sql ele lê a tabela de cdc do sql e
ele cria automaticamente lá tem um
processo mais enterprise até aí tudo bem
estamos todos
aí a gente está tudo a dormir eu não
estou preocupado com vocês agora então
beleza debysium como eu comentei o
conector na verdade a gente vai conectar
a tecnologia do cdc que está habilitado
então vai ter alguns pré -requisitos por
exemplo no caso do mysql eu tenho que
estar com o binlog habilitado no caso do
postfix eu tenho que usar o replication
mode igual a logical e do sql server eu
tenho que estar com o cdc habilitado
carrega e produz o que ele tem aqui de
interessante ele tem um decimal handle
mode trabalhar com com dado float
numeric seja o que for o todo stone
tombstone muito importante o tombstone
com delete isso aqui se habilita do ou
falso
o que que isso faz tá com um delete
acontece como eu comentei o que ele vai
fazer ele vai pegar a chave key e vai
botar a chave igual a 1 e vai zerar
e na verdade vai fazer isso aqui na
verdade no cdc ele vai pegar a chave e
vai falar assim key 2 key 1 before e vai
colocar o valor lá valor pra lá lá
e aqui é o after quando eu falo esse
cara igual a true ele vai setar pra não
aparecer nada ele vai ficar só assim ele
não vai mostrar o before nem o after vai
mostrar vai mostrar só o último
resultado então ele vai marcar como
topstone aquele cara lá ora esse cara
aqui foi deletado e você pode
desabilitar ou não você pode deixar
habilitado pra ver como é que tava antes
como modando depois que ele hoje não
habilita tá ou você pode falar assim
cara eu não quero ver delete pra mim não
importa aqui no meu pipeline e eu coloco
ele como só mesmo mostrando o valor em
branco no qual ele não vai fazer nada
beleza e eu tenho algumas smt's
customizadas que as smt's eu baixo junto
com o meu conector então dentro do
conector do jato conector do dbcdc eu
vou ter minha smt que eu vou mostrar
aqui daqui a pouco beleza então vamos
pra demo nós estamos quase na reta final
depois eu vou mostrar a REST API eu vou
mostrar vamos mostrar a REST agora
porque a gente fica só no conector
porque o REST é bem simples vou mostrar
o REST PROXY e a gente termina aí quando
que o registro é marcado como tombstone
quando ele é deletado quando eu tenho a
operação de delete para o cdc então o
cdc ele chegou o delete OP eu vou
mostrar lá pra vocês OP D ele vai marcar
como tombstone se tiver é I4 senão ele
vai deixar lá delete vai ter os dois
registros BEFORE e AFCO então vamos
pegar o PROXY aqui para a gente dar só
na demo para a gente não perder muito
tempo o REST PROXY ele é justamente a
forma de trazer o pessoal que trabalha
mais com REST que quer fazer coisas mais
simples para trabalhar com o caso então
o REST PROXY é um componente novo é um
cluster separado em que eu posso mandar
comandos do REST para esse cara e ele
vai fazer a tradução para produzir dados
pegar dados administrativos consumir só
que ele é bem
mais simples essa palavra certa é
limitado então geralmente é usado para
quando eu quero trabalhar de forma mais
simples eu tenho um comando REST GET PUT
DRIFT seja qual for só que o meu a minha
interação é muito simplificada eu não
quero fazer uma aplicação robusta como é
que ele funciona por exemplo FRONT END
eu crio uma aplicação FRONT END para
interagir com meu PROXY que é aquele que
vai interagir com meu BROKER eu vou
criar uma aplicação complexa eu vou
interagir por exemplo eu vou consumir
dados aqui mandar dados no meu FRONT
para o CAF eu não quero criar um PRODUCE
em Java Python eu quero simplesmente
pegar a minha aplicação aqui adicionar
um método e mandar esse dado que você
tem do FRONT para o CAF então eu posso
dar o PROXY para isso aí eu coloquei a
aplicação REACT por exemplo que não tem
seriam linguagens que não tem suporte ao
a linguagem do CAF ao protocolo do CAF
são muito poucas hoje em dia são muito
poucas e aqui eu quero fazer um script
eu quero fazer um SH para trabalhar com
o CAF e eu quero na verdade não ter esse
SH pronto dentro do meu do meu do meu
esse SH interno do CAF e eu quero usar o
PROXY para poder mandar essa informação
pelo SH então eu trabalho de novo um
CLUSS de PROXY que ele vai comunicar com
o CAF beleza justamente isso aqui é bem
simples a gente só precisa saber ele
mesmo prática usa -se muito pouco e de
novo ele é ele é bem limitado eu não
consigo fazer tudo que a SURFACE um
framework casos bem específicos.
Eu falei, front -end e geralmente até
mesmo script, a gente costuma
desenvolver alguma coisa e poder
trabalhar.
Então, não justifica.
Mas ele está lá, um componente que é
utilizado, que você pode estar
utilizando, que é o REST Proxy, que você
pode subir.
No caso do correspondente dele no
StreamZ, é o Bridge.
Para quem tiver curiosidade, que seria o
REST Proxy no StreamZ, é o Bridge.
Quando você ver Bridge lá, na verdade
ele vai se relacionar com o servidor de
REST Proxy.
Beleza, vamos para a demo.
Gente, todo mundo online?
E agora a gente vai mostrar o conector.
E aí eu preciso de tempo.
Eu preciso de tempo.
Eu preciso mostrar os bancos primeiro
para vocês.
Todo mundo baixa a latência e
respondendo em meio de
segundo.
Mandei a request.
Vamos ver se estão respondendo o
metadado
aí.
Então vamos lá.
Então eu tenho, vamos mostrar isso aqui.
Aqui também.
Isso aqui não tem link.
Beleza.
Então aqui, gente, eu tenho o meu SQL
Server, que está habilitado o CDC.
Eu vou mostrar para vocês aqui.
Deixa eu só abrir aqui um query.
E eu tenho esse cara aqui, salvo.
O error.
Aqui eu coloquei para vocês.
Tem a pasta Mongo, SQL Server e
Postgres.
Beleza?
Vamos no SQL Server aqui.
Readme.
Eu tenho algumas informações aqui para
vocês.
Não é nesse Readme que eu estou
querendo.
Acho que esse cara aqui eu coloquei.
Eu tenho uma query aqui.
Aqui eu tenho a query para ver se ele
está habilitado.
Vamos ver se está conectado no certo.
Estou.
Copiado, na verdade.
Acabou o chain.
Então aqui eu estou com o CDC.
Vamos habilitar as minhas duas tabelas.
E o que essas tabelas têm?
Se vai ter isso, vou cc account.
Account transactions.
Então eu tenho aqui a informação de
transação, ID, o account number, o tipo,
depósito, se for um pagamento, se for
uma retirada.
O valor, uma descrição e um date.
Mas aqui eu tenho também eu criei um da
transação, eu criei quando o registro
foi criado enquanto foi o update.
Aqui, como eu sou um desenvolvedor
legal, eu já trouxe o update at, ou
seja, quando sofrer uma alteração, cria
para mim aqui um current time stamp de
quanto aconteceu.
De novo, vamos sofrer, né?
Eu quero anunciar para vocês para não
sofrer.
Então aqui, não precisaria, para esse
caso, você descer, tá?
Mas eu já gosto de colocar para todos,
porque se eu precisar de mudar a minha
demonstração, eu já tenho isso aqui
engatilhado.
Então aqui o account, mesma coisa, o
account number desse, do account de
transação, vai ser o mesmo também, tá
gente?
Eu criei um arquivo texto, que eu
poderia utilizar para fazer o join entre
eles se precisar.
Então aqui eu tenho o ID, vai aqui, ó.
Isso aqui é um campo sequencial dentro
do SQL.
E toda vez que eu tiver um novo insert,
ele vai criar lá dentro, tá?
Os dados.
Tá vendo?
Então aqui eu tenho tudo pronto aqui
para a gente poder trabalhar com o CDC.
Botou, né?
Beleza.
Então aqui eu estou com o CDC prontinho.
Só que eu tenho um mongo, deixa eu
mostrar um pouco.
Mongo, mongo, mongo.
E eu sou meio orelha, e eu criei cada
ano uma ideia
diferente.
Então aqui eu tenho o mongo, vou dar
refresh aqui.
Eu tenho 14 mil documentos aqui nesse
cara, e esse cara aqui tem 7 mil.
Então tem 7 mil e 100 usuários, tá?
De histórico de empregador, eu tenho 14
mil, que é o histórico daquele usuário,
ou seja, se ele mudou de emprego e tal,
porque eu quero oferecer para ele alguma
coisa, algum convênio que a empresa dele
pode ter.
E eu tenho aqui um endereço também
separado.
Então endereço, aqui ó, user ID e user
ID aqui.
Então aqui também eu estou dentro do
mongo, que eu estou no mongo.
E também, para a gente concluir o nosso
dataset, eu tenho aqui no post.
Então no post, eu vou usar até um delete
aqui, que eu estava limpando, voltando
de novo e tal.
Eu tenho aqui um conector, vou conectar
de
novo.
Eu tenho 40 mil registros de cartão de
crédito e de transações.
Vamos ver quanto a gente tem.
4 mil.
Vou dar uma exceção aqui maior para a
gente poder ver esse cara rodando aqui.
Vai testar esse cara aqui, CC
Transactions.
Então eu tenho normal, né?
Eu tenho coisas no Oracle, eu tenho
coisas no S -Reserve, eu tenho coisas no
Post, eu tenho coisas no mongo, né?
Vida normal é de qualquer EG de dados.
Beleza.
Vamos para os nossos conectores.
Deixa eu abrir aqui.
Deployment.
Aqui deixa o deployment.
Eu vou ter como vocês subirem os bancos,
tá?
Tem aqui os IEMOs.
Se eu subir no Kubernetes, testar local.
Aqui tem a execução, caminhozinho aqui
bonitinho, só executar.
E aqui em Streams, eu tenho o meu
conector.
Olha que maravilha.
E aqui, gente, eu vou abrir um mongo
normal, tá?
Vamos pegar um mongo normalzão.
Olha como é que é fácil trabalhar com o
conector.
Classe, teste que eu vou abrir, tá?
Configuração que eu vou trabalhar.
Beleza?
E aqui, teste que eu posso abrir,
quantidade de teste que eu quiser, para
eu poder paralisar aquele processo.
Pergunta.
Vocês que trabalham com Devisão CDC,
valendo o...
Eu vou falar quando eu tiver presencial,
eu vou falar que tá
bagunça.
Valendo uma garrafinha de engenharia de
dados acadêmica que eu tenho aqui.
Tá guardado aqui, tá até na caixinha.
Vou levar no presencial.
Vou deixar até assim, ó.
Vou até ver quem vai responder primeiro.
Vou deixar assim, pra tá gravado.
É...
Quando eu tenho um um conector Devisão
CDC, qual o máximo de testes que eu
posso ter?
Vamos ver se vocês já sabem isso antes
de eu explicar, né?
Porque esse aqui, eu não expliquei isso
ainda.
Vou explicar agora com ele.
Mas vocês já sabem, né?
Porque vocês já sabem.
Qual o máximo de testes eu posso ter em
Devisão CDC e por quê?
Eu vou fazer mais uma garrafinha, né
gente?
Da engenharia de dados acadêmica, são
poucas que tem no mercado aí.
Mesmo hoje, broker?
Não.
Depende do número de tabelas.
Por quê?
Eu leio.
Você acertou, tá?
Já foi a resposta certa.
Você voltou a pergunta pra mim, mas por
quê?
Vamos ver se você vai saber o porquê.
Você fecha o processo.
A garrafinha é sua.
Eu sei que você não é de BH, eu vou
deixar uma pessoa depois e eu te passo.
Vou deixar o Alexandre te passar.
Ele resolve.
Sabe por quê?
Não necessariamente.
Não é motivo não.
Pensa que a TESC eu posso paralisar né?
Eu posso abrir um tópico ou mais.
É quantidade de tabelas?
Sim.
Eu vou sortear outra pergunta nessa
garrafinha que ninguém aceitou pra me
deixar bem claro.
O Devisão CDC eu falo a quantidade de
tabelas porque ele é baseado em log, tá?
Ele vai abrir a quantidade de log.
Então todos os conectores dele vai ter
log.
Você só pode colocar a quantidade de
TESCs pela quantidade de tabelas que
você vai querer no conector.
Se eu tiver uma tabela no conector, uma
TESC.
Porque a forma como ele trabalha é como
log B.
Então ele vai alocar a TESC só pra
aquilo.
Eu não posso paralisar aquele processo.
Então é uma coisa que eu tenho como...
Não é negativo não, tá?
Eu gosto, por exemplo, de fazer um pra
um.
Eu gosto sempre de ter um conector pra
cada tabela e um pra cada tópico.
Então acaba que pra mim eu sempre vou
ter um como TESC.
Então se você colocar dois, não vai
funcionar.
Não vai funcionar.
Não vai fazer nada.
Vai ficar árduo.
Quase eu.
Vamos ensinar a próxima e a gente pega.
Beleza, gente.
Então aqui, ó.
Configuração.
Essa aqui a gente não muda, tá?
Converter.
Muda não.
Muda sim.
Eu vou passar pra árvore o TESC, mas
essa estrutura aqui não muda.
O que muda é pra baixo.
Conexão RI.
Aqui é a conexão do meu Mongo.
Como eu tô local, ou seja, vou rodar
dentro do Kubernetes o meu conector, ele
já vai buscar o nome de serviço do meu
cluster.
Do meu MongoDB.
Nome da base.
É a collection startup.
Só que ainda não tá legal.
Vamos ver um...
Vai rodar?
Vai.
Vamos colocar aqui um nome diferente.
Vai rodar, mas ainda acho que tá meio
ruim.
Não tô gostando não.
Particularmente falando.
Aí eu vou vir aqui que eu tenho tudo
prontinho pra vocês.
Legal.
Eu vou abrir o tempo aqui.
Eu vou baixar aqui.
E aqui eu vou rodar aquele emu, tá?
Ele vai criar.
Ele vai colocar.
Ele pegou o mesmo nome lá do...
Eu esqueci de colocar o nome.
Kget Kafka Connectors.
Tem um parado aqui.
Eu tentei porque.
Depois eu vejo.
Vou deletar esse cara aqui.
Aqui esse cara que tá agora.
Ok.
Kget.
Kget.
Kget.
Esse nome.
Menos.
Tá funcionando aqui.
Que legal.
Ele, ó.
Conectou.
Tá rodando nesse Worker ID.
A task é zero, mas tá no estado.
Não tá fazendo nada.
O nome do tópico é esse tópico aqui.
Só que eu forcei a mudança de tópico.
O ideal, gente, nessa modificação que a
gente faz, é sempre colocar um nome
novo, tá?
Que pode ser que ele dê pau por conta
disso.
É.
Vai dar pau por conta disso.
Então eu venho aqui.
Eu vou trocar o nome pra blá, blá, blá.
Poder...
Funcionar.
Porque eu já testei isso várias vezes.
Kget Connectors.
Aqui, ó.
Já tá aqui, ó.
Blá, blá, blá.
Tá aqui.
Deixa eu pegar aqui.
Kget.
Na verdade, deixa eu usar o terminal.
Porque o terminal é mais rápido.
Terminal aqui é bem mais rápido.
Aumentar ele um pouquinho pra vocês
poderem ver.
Vamos abrir.
Tá elogiando isso aqui agora.
Se me faz essa.
Beleza.
Eu faço aqui, ó.
Menos só.
Vamos ver se ele vai...
Criou.
Tá vendo, ó?
Conector Status Running.
Task Running.
Tipo Source.
Task 1.
Perfeito.
Rodando.
Se eu pegar agora aqui o meu Consumer.
Vou pegar um Consumer aqui pra gente
poder ler aqueles dados lá do Mongo, né?
Como é que eu falei que é o nome do
tópico?
Tá aqui o tópico aqui.
Bem ruim esse nome, né?
E vamos carregar.
Blá, blá, blá.
Vai demorar.
Aí carregou.
Vai até o final pra gente poder ver.
Então aqui, ó.
Comparar o servilhote.
Isso aí vai ficar aí na hora da morte.
É...
Aqui, ó.
Começa aqui, ó.
Create Time.
Aqui eu não tô trazendo headers.
Eu não consigo acessar o metadado de
headers aqui.
Schema.
Gente, é bem feião pra gente olhar aqui
e processar isso aqui.
Dependendo do que você for mexer.
É bem chato, tá?
É um schema.
Aqui o payload.
Tá, mas é...
Não tá legal não.
Vamos melhorar esse cara aqui daqui a
pouco.
Então tem aqui os dados, olha.
Monsalves, e -mail, tal.
Então...
Vou mexer esse cara aqui.
Acho que esse aqui é melhor.
Vou mexer nesse aqui, ó.
Esse aqui eu vou mostrar o jdbc.
Na sexta -feira a gente mostra o MongoDB
processado.
Na verdade eu vou pegar...
Que eu vou melhorar isso aqui no
processamento.
Vamos mexer no que tem que processar,
né?
Vamos mexer no negócio aqui.
Então aqui, ó.
Eu tô usando o jdbc.
Trouxe o dado.
Aqui eu tô usando, ó.
Aqui, ó.
Avro.
Tô conectando no Postgres.
Eu tô trazendo essa tabela aqui, ó.
Do modo increment.
Lembra que eu criei aquela tabela lá?
Exatamente pra trazer aquele dado lá
dentro.
Então eu vou mudar o nome aqui.
Pra gente não ter o mesmo erro.
001 Eu vou trocar o nome dele.
Eu vou trocar o nome dele.
Vamos ver como é que tá o nome dos
tópicos aqui.
Que eu não lembro mais.
Vamos listar aqui os tópicos.
Tudo bonitinho aqui.
Vamos ver que não se tá...
Vamos melhorar esse tópico.
CCTransaction.
Então vamos deixar ele assim.
Só pra eu poder...
Mostrar pra vocês ele é zero.
Depois eu mostro ele zoado.
E eu já mostro o outro bonitão.
Aqui eu vou colocar 001.
Opa.
Cadê o seu amigo?
Nossa, 001.
Raço.
E aqui meus alunos.
Esse cara tá...
De novo, não quer dizer que vai
funcionar.
Quer dizer que é legal, tá?
Aqui subiu, criou.
Vou validar.
001.
E...
Minus...
Eu tô lendo o...
O retorno.
Aqui tá carregando ainda.
Demora um pouco mais do que os outros.
Eu já percebi isso já.
Pra estanciar.
Mostrar o tópico.
Demora um pouquinho mais.
Então vamos deixar ele aqui.
Pra gente não perder tempo.
Eu quero mostrar pra vocês aqui a
melhoria.
Que ainda não tá legal.
Vamos...
Vamos ler esse logo aqui.
Eu vou mostrar a melhoria que a gente
pode fazer.
Usando SMT.
Então cadê o meu amigo?
Aqui ó.
Não.
Esse aqui é o usuário.
E aqui eu vou ler...
Esse cara.
Reparem.
Ele não tem chave.
Primeiro que ele não tem chave.
E outra coisa.
Ele não tem algumas informações de
metadados que eu preciso.
Ele não tem informação, por exemplo...
O mouse tá zoado.
Ele não tem informação de onde que vem.
Depois eu vou fazer o cache também.
Eu vou fazer só por enquanto que tá
pronto aqui.
Olha só.
Vou pegar o mesmo.
E vou fazer uma modificaçãozinha aqui.
Eu vou colocar 001.
Pra gente poder saber que esse aqui é
novo.
Ó.
Esse cara aqui.
Dá até aqui.
Dá a mesma coisa.
Aí aqui ó.
Aqui gente é o SMT.
Transforms.
É o que eu chamo de SMT.
Tá bom?
Eu vou extrair aqui...
O...
O campo inteiro.
Que na verdade minha chave aqui é ID.
Então ele é no campo inteiro.
Então eu vou criar a chave.
Vou popular essa chave pro campo
inteiro.
Eu vou inserir a mensagem do tópico.
E eu vou falar de onde que ele vem.
Porque muitas vezes.
E isso é dados de transformação de
metadados.
Eu quero já criar um label.
Criar um rock desse cara.
Vamos ver esse cara funcionando.
Como é que vai ficar agora.
Então eu vou salvar aqui.
E eu vou carregar.
Deixa eu trocar o nome aqui.
Fazendo o mesmo erro.
001.
E eu vou rodar esse cara aqui.
Promess.
E...
Vou subir ele.
Ele vai inferir o tipo.
Como assim?
Seria um tipo.
Tipagem de dado?
Vai.
Como o conector ele é uma coisa mais
embedada.
Ele não sabe esquema.
Ele vai ler.
Ele vai inferir.
Vai entender o que que ele vai dar.
Por isso que a gente tem que ter algumas
configurações.
De numeric handle.
Tem umas coisas bem chatas aqui.
Eu gosto de trazer geralmente ele cru.
E eu processo uma parte do
processamento.
Lá eu trago ele mais prontinho.
Porque pode acontecer esses erros.
Ele pode vir com esquema.
Com a tipagem errada.
Nós temos o meu improvement.
Que eu acho que é com o número.
001.
20.
Esse cara aqui.
20.
Eu aumentei também para 4 tasks esse
cara aqui.
Ou seja, se eu mandar mais dados.
Então ele vai conseguir responder mais
rápido.
Lá.
Menos o item.
Mas ele já está concreado já.
Enquanto isso.
Como eu sou bem ansioso.
Eu já vou fazer uma inserção.
.
Lá no meu banco.
De 5 mil registros.
Eu vou deixar rodando.
E a gente vai vendo aqui.
Se meu cara já está carregando.
Ele vai criar.
Esperar um pouquinho para ele criar o
top.
Ainda está.
Como eu falei um pouco mais lento.
Poder fazer.
Só vou mostrar o CDC aqui.
E a gente finaliza com as perguntas.
Se tiver alguma pergunta.
Eu deixo para amanhã.
E a gente abre mais cedo amanhã.
Como eu comentei.
A gente abre 6 e meia, 7 horas.
Hoje eu abri 6 e meia.
Criou.
E aí meus amigos.
Olhem isso aqui.
Eu vou ler.
Esse cara.
Eu quero ler esse cara.
Olha ele.
Olha como ficou.
Aqui eu tenho o ID na frente.
Agora eu tenho uma chave.
Eu tenho a informação de onde que é.
Eu tenho também dentro aqui.
A informação de qual top.
Se por algum motivo eu estou lendo.
Estou fazendo.
Eu consigo extrair esse do valor também.
Então eu tenho algumas informações bem
interessantes.
Aqui agora.
Depois eu vou melhorar esse nosso SMT
aqui.
Que a gente pode fazer uma conversão.
Por exemplo.
Date time aqui.
Desse long.
A gente pode estar melhorando algumas
coisas.
Nesse cara aqui.
Para poder fazer juntos.
Beleza.
CDC quero dizer de vocês.
Esse aqui.
Se não gostar.
O CDC.
Deixa eu até modificar uma coisinha
aqui.
É.
Como eu comentei.
Dois.
Por que?
Duas tabelas.
Beleza.
Schema Registry com AVA.
Vamos usar a Schema Registry.
Aqui.
São esquemas.
São informações referentes.
A posicionamento que ele faz.
Internamente.
Ele cria também.
O esquema nativo dele.
Aqui eu tenho um decimal handle.
Para poder pegar.
E aqui eu vou colocar.
Aqui são configurações um pouco mais
avançadas.
De quantas vezes que eu vou interagir
com o banco.
O meu corretor vai ficar batendo o tempo
inteiro.
Qual que vai ser o back size.
Lembra do back size.
Quando que eu vou trabalhar em fila.
Quando que eu vou fazer o fetch.
Do dado lá dentro.
Então ele vai batendo essas
configurações aqui.
Em que o menor.
Sempre vai ser o mais correspondente.
Mas aqui que é importante.
Lilian você perguntou.
Essas configurações aqui são
interessantíssimas.
Por que?
Aqui eu faço o wrap.
O wrap do meu JSON.
Eu vou fazer sem.
Deixa eu tirar isso aqui.
Para a gente ver os dois.
Vou fazer o.
Basic.
Eu vou tirar esse cara aqui.
Nós vamos criar ele com outro nome.
Para vocês poderem ver como é que ele
cria.
Esse aqui é importante.
Eu já criei já.
Ele bobadão.
Então eu vou colocar aqui 2.
No basic.
E eu vou subir ele como basic.
Perfeito.
E aí eu vou criar rapidinho.
Para a gente não perder tempo.
Eu quero liberar vocês.
Aqui eu vou usar.
O cdc.
Para carregar os dados que estão.
Lá no meu.
Meu amigo.
Ele criou aqui.
Deixa eu ver.
Se já subiu.
Basic.
Basic.
Basic.
Basic.
Basic.
Opa.
Minus o e o.
Beleza.
Espera subir por enquanto.
Eu vou deixar já pronto o JavaScript.
Para a gente poder ler.
Para a gente poder ver como é que ele.
Como é que ele traz agora.
Para a gente ver como é que ele vai
trazer
depois.
Deixa eu ver se eu tenho pronto aqui.
Vamos pegar aqui.
Beleza.
Então aqui eu vou trazer o account.
Vamos ver.
Como é que vai estar essa belezura aqui.
Before.
Nada antes.
Nada antes.
Porque não tem.
Vamos pegar aqui.
Operação.
Aqui é só de inserção.
R.
R inserção.
O update de delete.
Mas.
Qual legal não.
Aqui tem before e after.
Aqui tem before e after.
Como é que ele vai ficar.
Quando eu fizer isso aqui.
Eu vou chamar de ADV.
ADV.
ADV.
Beleza.
Então vamos.
Mudei aqui.
Agora.
Massa.
Agora aqui.
Beleza.
Vou até pegar o outro aqui.
Para a gente rodar aqui bem.
Vai ser mais rápido.
O ADV.
Subiu.
Meu amiguinho.
Você aqui.
Só que aí.
Eu vou rodar no meu tempo.
Aqui.
Porque a gente vai conseguir ver melhor.
Eu acho.
Primeiro.
Que vale ressaltar aqui.
Isso aqui é legal caramba.
Vamos pegar.
Um em cima do outro aqui.
Para a gente poder ver isso aqui.
Eu vou subir aqui.
Cadê.
Vou rodar de novo.
Before.
After.
Não tem aqui mais.
Por que.
Porque eu fiz ele de forma dele ser.
Unwrap.
Então ele quebrou na coluna.
E traz aqui sempre o dado que vai ter
presente.
Não vai ter nulo aqui mais.
Já começa por aí.
Adicionei a questão do message topic.
Aqui de novo.
Então.
Eu adicionei algumas informações aqui.
E tirei algumas informações.
Que eu não estava tão utilizando.
Justamente para eu trazer.
Então dentro do SMT.
Lílian estava com mais dificuldade.
Você perguntou.
Eu tenho aqui.
Eu adicionei os campos.
Optable.
Traz para mim esses campos.
Operação.
Tabela.
Minissecondos.
Então adicionei esse cara aqui.
Era JSON.
Before e After.
Eu quebrei o tabular e falei.
Eu quero que você mantenha para mim.
Optable e Source.
Se não tiver nada.
Ele vai manter o Before.
Se tiver o After.
Ele vai manter a última atualização.
Meio que um log compacto.
Só que ele faz um log compacto.
Baseado nos eventos que estão
acontecendo.
Então.
No caso do Update.
Tem do Before e After.
Como ficar no RAM.
Eu vou mostrar só o Update atual.
Ele vai mostrar os outros.
Vai mostrar o Update do último dado.
Então.
Isso é uma forma.
Já que eu sei.
Eu quero pegar o último dado.
Você faz o que você faz com o SMT.
Bem simples.
Então é isso pessoal.
Eu queria mostrar para vocês.
Se vocês não tem acesso a todos os
códigos.
Para testarem.
De novo.
Eu recomendo testarem.
Pega o ambiente.
Teste.
Ver o resultado.
Valida.
De novo.
Eu prefiro que vocês testem lá.
Depois do dia 4.
Porque eu vou explicar o Consume.
Então vocês vão ter o Pipeline completo.
Mas se vocês quiserem.
Amanhã a gente já começa.
Já a distribuir o Git.
Mas eu de novo.
Eu prefiro que vocês sempre tenham.
Lembrando que o dia 4 e 5.
Eu não vou liberar amanhã.
Porque eu não estou mexendo neles ainda.
Eu sempre deixo para o dia.
Principalmente para essa coisa nova.
Eu dou uma olhada se tem alguma coisa
para testar.
Então não libero não.
Mas o dia 1 e 2.
E 3 vocês vão ter acesso.
Beleza meus amigos e amigas.
Dúvidas.
Se vocês querem perguntar.
Querem deixar para amanhã.
O que vocês querem fazer.
Conta para mim aqui no chat.
Minha parte finalizou.
De novo.
Cuidado com SMT.
Muito cuidado com SMT.
Não usem a conta direita.
Usem quando precisar.
Validem.
Testem primeiro.
Para depois vocês.
Subirem em produção.
Não mudem o que já existe.
Sempre falo isso em qualquer
treinamento.
Tomem cuidado.
E sempre testem primeiro.
Então a gente já entendeu a parte de
ingestão de dados.
Amanhã a gente já faz processamento.
Então vou pegar esses dados que a gente
trouxe.
Do Mongo.
Do SQL Server.
De Producer.
A gente vai começar a modelar o nosso
evento.
Tudo acontecendo em tempo real.
Então caiu o dado no banco.
Automaticamente já cai no carro.
Pelo Connect.
A gente modifica.
Ele usando o Byte2X.
E usando o Flink.
Vou usar esses dois caras para mostrar.
A gente vai entrar em detalhes de Kafka
Streams.
A gente vai entrar em detalhes de outras
tecnologias.
De processamento que são core.
Para vocês entenderem os conceitos.
Todos eles regem os mesmos conceitos.
Pessoal.
Então é isso.
A gente se vê amanhã então.
Então amanhã eu abro.
Alguém quer perguntar alguma coisa?
Se quiserem eu tenho tempo para
perguntar.
Eu abro aqui.
Se tiver.
Então tá.
Eu vou considerar que nós temos amanhã.
Amanhã então cometa a informação.
Traz amanhã mais coisas para a gente.
E amanhã a gente fala processamento.
Então amanhã vai ser bem legal.
Particularmente eu gosto bastante.
Obrigado gente.